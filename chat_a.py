#!/usr/bin/env python
# coding: utf-8

# In[10]:


import pandas as pd
import torch
from sentence_transformers import SentenceTransformer, util
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F
from collections import defaultdict
from datetime import datetime
import random
import re
from css import log_and_render
import streamlit as st, pandas as pd, json, requests
# -------------------- ëª¨ë¸ ë° ë°ì´í„° ë¡œë”© --------------------
# ëª¨ë¸ ë¡œë”© ë¶€ë¶„ì„ í•¨ìˆ˜ë¡œ ë§Œë“¤ê³  ë°ì½”ë ˆì´í„° ì¶”ê°€
@st.cache_resource
def load_sbert_model():
    print("SBERT ëª¨ë¸ ë¡œë”© ì¤‘... (ì´ ë©”ì‹œì§€ëŠ” í•œ ë²ˆë§Œ ë³´ì—¬ì•¼ í•©ë‹ˆë‹¤)")
    # 'jhgan/ko-sroberta-multitask' ëŒ€ì‹  ë” ê°€ë²¼ìš´ ë‹¤êµ­ì–´ ëª¨ë¸ë¡œ ë³€ê²½
    return SentenceTransformer("distiluse-base-multilingual-cased-v1")

@st.cache_resource
def load_sentiment_model():
    print("ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë”© ì¤‘... (ì´ ë©”ì‹œì§€ëŠ” í•œ ë²ˆë§Œ ë³´ì—¬ì•¼ í•©ë‹ˆë‹¤)")
    # 'hun3359/klue-bert-base-sentiment' ëŒ€ì‹  ë” ê°€ë²¼ìš´ ëª¨ë¸ë¡œ ë³€ê²½
    model = AutoModelForSequenceClassification.from_pretrained("monologg/distilkobert")
    model.eval()
    return model

@st.cache_resource
def load_tokenizer():
    print("í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘... (ì´ ë©”ì‹œì§€ëŠ” í•œ ë²ˆë§Œ ë³´ì—¬ì•¼ í•©ë‹ˆë‹¤)")
    # 'hun3359/klue-bert-base-sentiment' ëŒ€ì‹  ë” ê°€ë²¼ìš´ ëª¨ë¸ë¡œ ë³€ê²½
    return AutoTokenizer.from_pretrained("monologg/distilkobert")


@st.cache_data(show_spinner=False)
def load_csv_any(p):
    return pd.read_csv(p) if str(p).startswith(("http://","https://")) else pd.read_csv(p)

trip_url = st.secrets.get("TRIPDATA_URL")
if not trip_url:
    st.error("TRIPDATA_URL ë¯¸ì„¤ì •: Streamlit Secretsì— URLì„ ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

travel_df = load_csv_any(trip_url)
festival_df = pd.read_csv("ì „ì²˜ë¦¬_í†µí•©ì§€ì—­ì¶•ì œ.csv")
external_score_df = pd.read_csv("í´ëŸ¬ìŠ¤í„°_í¬í•¨_ì™¸ë¶€ìš”ì¸_ì¢…í•©ì ìˆ˜_ê²°ê³¼_ìµœì¢….csv")
external_score_df.columns = external_score_df.columns.str.strip()
weather_df = pd.read_csv("ì „ì²˜ë¦¬_ë‚ ì”¨_í†µí•©_07_08.csv")
package_df = pd.read_csv("ëª¨ë‘íˆ¬ì–´_ì»¬ëŸ¼ë³„_ê°œìˆ˜_07_08.csv")
package_df.columns = package_df.columns.str.strip()
master_df = pd.read_csv("ë‚˜ë¼_ë„ì‹œ_ë¦¬ìŠ¤íŠ¸.csv")

countries = travel_df["ì—¬í–‰ë‚˜ë¼"].dropna().unique().tolist()
cities = travel_df["ì—¬í–‰ë„ì‹œ"].dropna().unique().tolist()
    
def detect_location_filter(text, intent_score=None):
    def in_text_exact(word):
        return word in text
        
    master_cities_list = master_df["ì—¬í–‰ë„ì‹œ"].dropna().unique()
    master_countries_list = master_df["ì—¬í–‰ë‚˜ë¼"].dropna().unique()
    
    found_city = next((c for c in master_cities_list if c in text), None)
    found_country = next((c for c in master_countries_list if c in text), None)
    
    # 1. ì´ë¦„ì¡°ì°¨ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ intent_score í™•ì¸
    if not found_city and not found_country:
        if intent_score is not None and intent_score >= 0.70:
            return None, None, "intent"
        else:
            return None, None, "emotion"
        
    # 2. ëª…í™•í•œ ë„ì‹œ/ë‚˜ë¼ê°€ ìˆì„ ê²½ìš° â†’ region
    if found_city and not found_country:       
        match = master_df[master_df["ì—¬í–‰ë„ì‹œ"] == found_city]
        if not match.empty:
            found_country = match.iloc[0]["ì—¬í–‰ë‚˜ë¼"]
                              
    is_city_recommendable = found_city in cities if found_city else False
    is_country_recommendable = found_country in countries if found_country else False

    if is_city_recommendable or is_country_recommendable:
        return found_country, found_city, "region"
    return found_country, found_city, "unknown"
# -------------------- ê°ì • í‚¤ì›Œë“œ ì„¤ì • --------------------
klue_emotions = {
    0: "ë¶„ë…¸", 1: "íˆ´íˆ´ëŒ€ëŠ”", 2: "ì¢Œì ˆí•œ", 3: "ì§œì¦ë‚´ëŠ”", 4: "ë°©ì–´ì ì¸", 5: "ì•…ì˜ì ì¸",
    6: "ì•ˆë‹¬í•˜ëŠ”", 7: "êµ¬ì—­ì§ˆ ë‚˜ëŠ”", 8: "ë…¸ì—¬ì›Œí•˜ëŠ”", 9: "ì„±ê°€ì‹ ", 10: "ìŠ¬í””", 11: "ì‹¤ë§í•œ",
    12: "ë¹„í†µí•œ", 13: "í›„íšŒë˜ëŠ”", 14: "ìš°ìš¸í•œ", 15: "ë§ˆë¹„ëœ", 16: "ì—¼ì„¸ì ì¸", 17: "ëˆˆë¬¼ì´ ë‚˜ëŠ”",
    18: "ë‚™ë‹´í•œ", 19: "í™˜ë©¸ì„ ëŠë¼ëŠ”", 20: "ë¶ˆì•ˆ", 21: "ë‘ë ¤ìš´", 22: "ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ëŠ”",
    23: "ì·¨ì•½í•œ", 24: "í˜¼ë€ìŠ¤ëŸ¬ìš´", 25: "ë‹¹í˜¹ìŠ¤ëŸ¬ìš´", 26: "íšŒì˜ì ì¸", 27: "ê±±ì •ìŠ¤ëŸ¬ìš´",
    28: "ì¡°ì‹¬ìŠ¤ëŸ¬ìš´", 29: "ì´ˆì¡°í•œ", 30: "ìƒì²˜", 31: "ì§ˆíˆ¬í•˜ëŠ”", 32: "ë°°ì‹ ë‹¹í•œ", 33: "ê³ ë¦½ëœ",
    34: "ì¶©ê²© ë°›ì€", 35: "ê°€ë‚œí•œ ë¶ˆìš°í•œ", 36: "í¬ìƒëœ", 37: "ì–µìš¸í•œ", 38: "ê´´ë¡œì›Œí•˜ëŠ”",
    39: "ë²„ë ¤ì§„", 40: "ë‹¹í™©", 41: "ê³ ë¦½ëœ(ë‹¹í™©í•œ)", 42: "ë‚¨ì˜ ì‹œì„ ì„ ì˜ì‹í•˜ëŠ”", 43: "ì™¸ë¡œìš´",
    44: "ì—´ë“±ê°", 45: "ì£„ì±…ê°ì˜", 46: "ë¶€ë„ëŸ¬ìš´", 47: "í˜ì˜¤ìŠ¤ëŸ¬ìš´", 48: "í•œì‹¬í•œ",
    49: "í˜¼ë€ìŠ¤ëŸ¬ìš´(ë‹¹í™©í•œ)", 50: "ê¸°ì¨", 51: "ê°ì‚¬í•˜ëŠ”", 52: "ì‹ ë¢°í•˜ëŠ”", 53: "í¸ì•ˆí•œ",
    54: "ë§Œì¡±ìŠ¤ëŸ¬ìš´", 55: "í¥ë¶„", 56: "ëŠê¸‹", 57: "ì•ˆë„", 58: "ì‹ ì´ ë‚œ", 59: "ìì‹ í•˜ëŠ”"
}

kote_emotion_groups = {
    "ì‹ ë‚¨": [
        "ê¸°ì¨", "í¥ë¶„", "ì‹ ì´ ë‚œ", "ìì‹ í•˜ëŠ”", "ë§Œì¡±ìŠ¤ëŸ¬ìš´"  
    ],
    "ê°íƒ„": [
        "ê°ì‚¬í•˜ëŠ”", "ë†€ë¼ìš´", "ê°ë™ì ì¸", "ê²½ì™¸ê°", "ì‹ ê¸°í•œ", "ê°íƒ„" 
    ],
    "í¸ì•ˆí•¨": [
        "í¸ì•ˆí•œ", "ì•ˆë„", "ëŠê¸‹", "ì‹ ë¢°í•˜ëŠ”", "ì¡°ìš©í•œ"  
    ],
    "ì•ˆì •": [
        "ë¶ˆì•ˆ", "ë‘ë ¤ìš´", "ê±±ì •ìŠ¤ëŸ¬ìš´", "ì´ˆì¡°í•œ", "ì·¨ì•½í•œ", "ê¸´ì¥ëœ"  
    ],
    "ìœ„ë¡œ": [
        "ì™¸ë¡œìš´", "ê³ ë¦½ëœ", "ë²„ë ¤ì§„", "ìƒì²˜", "ë‚™ë‹´í•œ", "ì‹¤ë§í•œ", "ìŠ¬í””", "ìš°ìš¸í•œ", "ëˆˆë¬¼ì´ ë‚˜ëŠ”"
    ],
    "ê°ì •ì „í™˜": [
        "ë¶„ë…¸", "ë…¸ì—¬ì›Œí•˜ëŠ”", "ì•…ì˜ì ì¸", "íˆ´íˆ´ëŒ€ëŠ”", "ì—¼ì„¸ì ì¸", "í•œì‹¬í•œ", "ë‹µë‹µí•œ", "ì§œì¦ë‚´ëŠ”","ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ëŠ”"
    ],
    "í˜¼ë€íšŒë³µ": [
        "í˜¼ë€ìŠ¤ëŸ¬ìš´", "ë‹¹í˜¹ìŠ¤ëŸ¬ìš´", "ê³ ë¦½ëœ(ë‹¹í™©í•œ)", "í˜¼ë€ìŠ¤ëŸ¬ìš´(ë‹¹í™©í•œ)",
        "ë‚¨ì˜ ì‹œì„ ì„ ì˜ì‹í•˜ëŠ”", "ë¶€ë„ëŸ¬ìš´", "ë§ˆë¹„ëœ", "ì£„ì±…ê°ì˜"
    ],
    "í•´ë°©": [
        "ì„±ê°€ì‹ ", "ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ëŠ”", "ë‹µë‹µí•œ", "ì–µìš¸í•œ", "íƒˆì¶œí•˜ê³  ì‹¶ì€"
    ],
    "ê¸°ëŒ€ê°": [
        "ì„¤ë ˆëŠ”", "ê¸°ëŒ€ë˜ëŠ”", "ë‘ê·¼ê±°ë¦¬ëŠ”", "ê°„ì ˆí•œ", "í¬ë§ì ì¸"
    ],
    "ë¶€ì •": [
        "êµ¬ì—­ì§ˆ ë‚˜ëŠ”", "ì§ˆíˆ¬í•˜ëŠ”", "ë°°ì‹ ë‹¹í•œ", "ì¶©ê²© ë°›ì€", "í˜ì˜¤ìŠ¤ëŸ¬ìš´", "ê°€ë‚œí•œ ë¶ˆìš°í•œ",
        "í¬ìƒëœ", "ì¢Œì ˆí•œ", "ë°©ì–´ì ì¸", "íšŒì˜ì ì¸", "ì—´ë“±ê°"
    ]
}

klue_label_to_group = {}
klue_to_general = {}

# label â†’ group ë§¤í•‘ ì¤€ë¹„
for group, keywords in kote_emotion_groups.items():
    for word in keywords:
        klue_label_to_group[word] = group

# klue_emotionsì— ìˆëŠ” ê°ì • í‚¤ë“¤ì„ ê·¸ë£¹í™”
for klue_id, klue_label in klue_emotions.items():
    group = klue_label_to_group.get(klue_label, "ë¶€ì •")
    klue_to_general[klue_id] = group

emotion_override_dict = {
    # ìœ„ë¡œ
    "ê¸°ë¶„ì´ ì•ˆ ì¢‹ì•„": ("ìš°ìš¸í•œ", "ìœ„ë¡œ"),
    "ê¸°ìš´ì´ ì—†ì–´": ("ë‚™ë‹´í•œ", "ìœ„ë¡œ"),
    "í˜ë“¤ì–´": ("ìŠ¬í””", "ìœ„ë¡œ"),
    "ì§€ì³¤ì–´": ("ìŠ¬í””", "ìœ„ë¡œ"),
    "í”¼ê³¤í•´": ("ìš°ìš¸í•œ", "ìœ„ë¡œ"),
    "ì™¸ë¡œì›Œ": ("ì™¸ë¡œìš´", "ìœ„ë¡œ"),
    "ìš¸ì í•´": ("ìš°ìš¸í•œ", "ìœ„ë¡œ"),
    "í—ˆì „í•´": ("ìŠ¬í””", "ìœ„ë¡œ"),
    "ë¬´ê¸°ë ¥í•´": ("ìš°ìš¸í•œ", "ìœ„ë¡œ"),
    "ë§ˆìŒì´ í—ˆí•´": ("ë‚™ë‹´í•œ", "ìœ„ë¡œ"),
    "ëˆˆë¬¼ì´ ë‚˜": ("ëˆˆë¬¼ì´ ë‚˜ëŠ”", "ìœ„ë¡œ"),
    "ì†ìƒí•´": ("ì‹¤ë§í•œ", "ìœ„ë¡œ"),
    "ì˜ìš•ì´ ì—†ì–´": ("ìš°ìš¸í•œ", "ìœ„ë¡œ"),
    "ì§€ì¹˜ê³  í˜ë“¤ì–´": ("ìŠ¬í””", "ìœ„ë¡œ"),
    "ë§ˆìŒì´ ì•„íŒŒ": ("ìŠ¬í””", "ìœ„ë¡œ"),

    # ê°ì •ì „í™˜
    "ë‹µë‹µí•´": ("ì§œì¦ë‚´ëŠ”", "ê°ì •ì „í™˜"),
    "ì§œì¦ë‚˜": ("ì§œì¦ë‚´ëŠ”", "ê°ì •ì „í™˜"),
    "í™”ë‚˜": ("ë¶„ë…¸", "ê°ì •ì „í™˜"),
    "ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„": ("ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ëŠ”", "ê°ì •ì „í™˜"),
    "ìŠ¤íŠ¸ë ˆìŠ¤": ("ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ëŠ”", "ê°ì •ì „í™˜"),
    "ì§œì¦": ("ì§œì¦ë‚´ëŠ”", "ê°ì •ì „í™˜"),
    "í„°ì§ˆ ê²ƒ ê°™ì•„": ("ë¶„ë…¸", "ê°ì •ì „í™˜"),
    "í­ë°œí•  ê²ƒ ê°™ì•„": ("ë…¸ì—¬ì›Œí•˜ëŠ”", "ê°ì •ì „í™˜"),
    "ì—´ë°›ì•„": ("ë¶„ë…¸", "ê°ì •ì „í™˜"),
    "í™”ê°€ ì¹˜ë°€ì–´": ("ë…¸ì—¬ì›Œí•˜ëŠ”", "ê°ì •ì „í™˜"),
    "ë¨¸ë¦¬ ì•„íŒŒ": ("ì„±ê°€ì‹ ", "ê°ì •ì „í™˜"),
    

    # í¸ì•ˆí•¨
    "ì¡°ìš©í•œ ê³³": ("í¸ì•ˆí•œ", "í¸ì•ˆí•¨"),
    "ì¡°ìš©í•œ": ("í¸ì•ˆí•œ", "í¸ì•ˆí•¨"),
    "í•œì í•œ ë° ê°€ê³  ì‹¶ì–´": ("í¸ì•ˆí•œ", "í¸ì•ˆí•¨"),
    "ì‰´ ê³³": ("ì•ˆë„", "í¸ì•ˆí•¨"),
    "ë§ˆìŒì´ í¸í•œ ê³³": ("í¸ì•ˆí•œ", "í¸ì•ˆí•¨"),
    "í¸ì•ˆí•œ ì—¬í–‰": ("í¸ì•ˆí•œ", "í¸ì•ˆí•¨"),
    "íë§ì´ í•„ìš”í•´": ("í¸ì•ˆí•œ", "í¸ì•ˆí•¨"),
    "ì•„ë¬´ ìƒê° ì—†ì´ ì‰¬ê³  ì‹¶ì–´": ("ëŠê¸‹", "í¸ì•ˆí•¨"),

    # ê°íƒ„
    "ê°ë™ë°›ê³  ì‹¶ì–´": ("ê°ì‚¬í•˜ëŠ”", "ê°íƒ„"),
    "ê°ë™ì ì¸": ("ê°ì‚¬í•˜ëŠ”", "ê°íƒ„"),
    "ê°ë™": ("ê°ì‚¬í•˜ëŠ”", "ê°íƒ„"),
    "ë†€ë¼ìš´ ê²½í—˜": ("ê°íƒ„", "ê°íƒ„"),
    "ì‹ ê¸°í•œ ê±°": ("ê°íƒ„", "ê°íƒ„"),
    "ì¸ìƒì ì¸": ("ê°íƒ„", "ê°íƒ„"),
    "ê²½ì´ë¡œìš´": ("ê°íƒ„", "ê°íƒ„"),
    "ê°íƒ„í•  ë§Œí•œ": ("ê°íƒ„", "ê°íƒ„"),
    "ì™€ í•˜ê³  ì‹¶ì–´": ("ê°íƒ„", "ê°íƒ„"),

    # ì‹ ë‚¨
    "ì„¤ë ˆ": ("ì‹ ì´ ë‚œ", "ì‹ ë‚¨"),
    "ì‹ ë‚˜": ("ì‹ ì´ ë‚œ", "ì‹ ë‚¨"),
    "í–‰ë³µí•´": ("ê¸°ì¨", "ì‹ ë‚¨"),
    "ê¸°ëŒ€ë¼": ("ê¸°ì¨", "ì‹ ë‚¨"),
    "ì¬ë°ŒëŠ” ê±°": ("ê¸°ì¨", "ì‹ ë‚¨"),
    "ê¸°ë¶„ ì¢‹ìŒ": ("ê¸°ì¨", "ì‹ ë‚¨"),
    "ì¦ê±°ìš´ ì—¬í–‰": ("ê¸°ì¨", "ì‹ ë‚¨"),
    "ë“¤ëœ¬ë‹¤": ("í¥ë¶„", "ì‹ ë‚¨"),

    # í˜¼ë€íšŒë³µ
    "í˜¼ë€ìŠ¤ëŸ¬ì›Œ": ("í˜¼ë€ìŠ¤ëŸ¬ìš´", "í˜¼ë€íšŒë³µ"),
    "í—·ê°ˆë ¤": ("í˜¼ë€ìŠ¤ëŸ¬ìš´", "í˜¼ë€íšŒë³µ"),
    "ë§ˆìŒì´ ë³µì¡í•´": ("í˜¼ë€ìŠ¤ëŸ¬ìš´", "í˜¼ë€íšŒë³µ"),
    "ì •ë¦¬ê°€ ì•ˆ ë¼": ("í˜¼ë€ìŠ¤ëŸ¬ìš´", "í˜¼ë€íšŒë³µ"),
    "ë¨¸ë¦¬ê°€ ë³µì¡í•´": ("í˜¼ë€ìŠ¤ëŸ¬ìš´", "í˜¼ë€íšŒë³µ"),
    "ì •ì‹ ì—†ì–´": ("í˜¼ë€ìŠ¤ëŸ¬ìš´", "í˜¼ë€íšŒë³µ"),

    # ì•ˆì •
    "ì•ˆì •ì´ í•„ìš”í•´": ("ë¶ˆì•ˆ", "ì•ˆì •"),
    "ë¶ˆì•ˆí•´": ("ë¶ˆì•ˆ", "ì•ˆì •"),
    "ê¸´ì¥ë¼": ("ì´ˆì¡°í•œ", "ì•ˆì •"),
    "ë§ˆìŒì´ ë¶ˆí¸í•´": ("ê±±ì •ìŠ¤ëŸ¬ìš´", "ì•ˆì •"),
    "ì¢€ ì§„ì •í•˜ê³  ì‹¶ì–´": ("ì•ˆë„", "ì•ˆì •"),
    "ì•ˆì •": ("ì•ˆë„", "ì•ˆì •"),

    # ë¶€ì •
    "ì‚´ê¸° ì‹«ì–´": ("ì—¼ì„¸ì ì¸", "ë¶€ì •"),
    "ì¸ìƒì´ ì¬ë¯¸ì—†ì–´": ("ì—¼ì„¸ì ì¸", "ë¶€ì •"),
    "ì„¸ìƒì´ ì‹«ë‹¤": ("í™˜ë©¸ì„ ëŠë¼ëŠ”", "ë¶€ì •"),
    "ì„¸ìƒì´ ì‹«ì–´": ("í™˜ë©¸ì„ ëŠë¼ëŠ”", "ë¶€ì •"),
    "ë‹¤ ê·€ì°®ì•„": ("ë§ˆë¹„ëœ", "ë¶€ì •"),
    "ê·¸ëƒ¥ ì‚¬ë¼ì§€ê³  ì‹¶ì–´": ("ë²„ë ¤ì§„", "ë¶€ì •"),
    "ì˜ë¯¸ê°€ ì—†ì–´": ("í™˜ë©¸ì„ ëŠë¼ëŠ”", "ë¶€ì •")
}

# -------------------- ì˜ë„ê¸°ë°˜ í‚¤ì›Œë“œ --------------------
intent_keywords = {
    "ì‡¼í•‘" : ["ì‡¼í•‘", "ê¸°ë…í’ˆ", "ë“í…œ", "íŠ¹ì‚°í’ˆ", "ì‚¬ê³  ì‹¶ì–´", "ì‡¼í•‘ëª°", "í˜„ì§€ ë¬¼í’ˆ"],
    "ì‹¤ë‚´" : ["ì‹¤ë‚´", "ë¹„ ì˜¤ëŠ” ë‚  ê°ˆë§Œí•œ ë°", "ì‹¤ë‚´ ì¥ì†Œ", "ì‹¤ë‚´ ê´€ê´‘", "ì‹¤ë‚´ ë°ì´íŠ¸ ì½”ìŠ¤"],
    "ê°€ì¡±" : ["ê°€ì¡±", "ê°€ì¡±ë¼ë¦¬", "ê°€ì¡±ê³¼ í•¨ê»˜", "ì•„ì´ì™€ ê°ˆë§Œí•œ ë°", "ê°€ì¡±ì—¬í–‰", "ë¶€ëª¨ë‹˜ì´ë‘ ì—¬í–‰", "ê°€ì¡± ë‹¨ìœ„", "ì•„ì´ ë™ë°˜"],
    "ì›Œí„°íŒŒí¬" : ["ì›Œí„°íŒŒí¬", "ë¬¼ë†€ì´", "ì›Œí„° ìŠ¬ë¼ì´ë“œ íƒ€ëŸ¬", "ìˆ˜ì˜ì¥", "íŒŒë„í’€", "ì–´íŠ¸ë™ì…˜"],
    "ìì—°" : ["ìì—°", "í’ê²½ ì¢‹ì€", "ê³µê¸° ì¢‹ì€"],
    "ì „ë§" : ["ì „ë§", "ë·° ì¢‹ì€", "íƒ íŠ¸ì¸", "ê²½ì¹˜ ì¢‹ì€", "ì „ë§ëŒ€"],
    "í¬í† ì¡´" : ["í¬í† ì¡´", "ì‚¬ì§„ ì°ë‹¤", "ì¸ìƒìƒ·", "ì¸ìŠ¤íƒ€ìš©", "ì‚¬ì§„ ëª…ì†Œ", "í¬í†  ìŠ¤íŒŸ", "ì´ì˜ê²Œ ì°íˆëŠ” ê³³"],
    "í•´ì–‘ì²´í—˜" : ["í•´ì–‘ ì²´í—˜", "ìŠ¤ë…¸í´ë§", "ë‹¤ì´ë¹™", "ìˆ˜ìƒ ì²´í—˜", "í•´ì–‘ ì•¡í‹°ë¹„í‹°", "í•´ì–‘ ìŠ¤í¬ì¸ "],
    "ìˆ˜ì¡±ê´€" : ["ìˆ˜ì¡±ê´€", "ì•„ì¿ ì•„ë¦¬ì›€", "ë¬¼ê³ ê¸° ë³´ëŸ¬", "í•´ì–‘ ìƒë¬¼ ë³´ëŸ¬"],
    "ì¢…êµ" : ["ì¢…êµ", "ì›…ì¥í•œ ê±´ì¶•ë¬¼", "ì„±ìŠ¤ëŸ¬ìš´ ë¶„ìœ„ê¸°", "ëª…ìƒ", "ì¢…êµì ", "ê¸°ë„"],
    "ì„±ë‹¹" : ["ì„±ë‹¹", "ì„±ì§€ìˆœë¡€", "ì—­ì‚¬ ê¹Šì€ ì„±ë‹¹", "ëŒ€ì„±ë‹¹", "ê°€ìš°ë””"],
    "ì˜ˆì‹ì¥" : ["ê²°í˜¼ì‹", "ì›¨ë”© ì´¬ì˜", "ì›¨ë”©", "ì˜ˆì‹ì¥"],
    "ì»¤í”Œ" : ["ì»¤í”Œ", "ì—°ì¸", "ë°ì´íŠ¸ ì½”ìŠ¤", "ì—¬ìì¹œêµ¬", "ë‚¨ìì¹œêµ¬"],
    "ëœë“œë§ˆí¬" : ["ëœë“œë§ˆí¬", "ìœ ëª…í•œ ì¥ì†Œ", "ëŒ€í‘œ ëª…ì†Œ", "ë„ì‹œ ëª…ì†Œ", "ì‹œê·¸ë‹ˆì²˜ ìŠ¤íŒŸ", "ìƒì§•ì ì¸", "ê¼­ ë“¤ëŸ¬ì•¼ í•˜ëŠ”"],
    "ì—­ì‚¬" : ["ì—­ì‚¬ì ì¸", "ì›…ì¥í•œ ê±´ì¶•ë¬¼", "ì˜›ë‚  ê±´ì¶•ë¬¼", "ì—­ì‚¬", "ì „í†µ ê¹Šì€", "ìœ ì ì§€"],
    "ê¶ì „" : ["ê¶ì „", "ì›…ì¥í•œ ê±´ì¶•ë¬¼", "ì™•ì´ ì‚´ë˜", "ê³ ê¶"],
    "ë¬¸í™”ì²´í—˜" : ["ì „í†µ ì²´í—˜", "ë¬¸í™” ì²´í—˜", "ë¬¸í™”ì  ê²½í—˜"],
    "ë°•ë¬¼ê´€" : ["ë°•ë¬¼ê´€"],
    "ì˜ˆìˆ ê°ìƒ" : ["ì˜ˆìˆ  ì‘í’ˆ", "ì˜ˆìˆ  ì‘í’ˆ ê°ìƒ", "ì°½ì˜ë ¥ ìê·¹"],
    "ì²´í—˜ê´€" : ["ê³¼í•™ê´€", "ì‹¤ë‚´ ì²´í—˜"],
    "ê´‘ì¥" : ["ë„ì‹œ ì¤‘ì‹¬ì§€", "ì‚¬ëŒ ë§ì€", "ê´‘ì¥"],
    "ì‚°ì±…" : ["ì‚°ì±…", "ê±·ê¸° í¸í•œ", "ì‚°ì±…ë¡œ"],
    "ë¯¸ìˆ ê´€" : ["ë¯¸ìˆ ê´€", "ê·¸ë¦¼ ë³´ëŸ¬", "ì „ì‹œíšŒ ë°ì´íŠ¸", "ì•„íŠ¸ ê°¤ëŸ¬ë¦¬"],
    "ê³µì—°" : ["ì˜¤í˜ë¼", "ê·¹ì¥", "ì—°ê·¹", "ê³µì—°"],
    "ìœ ëŒì„ " :["ìœ ëŒì„ ", "ë°”ë‹¤ ìœ„", "í¬ë£¨ì¦ˆ", "ìˆ˜ìƒ ê´€ê´‘", "ë°° íƒ€ê³ "],
    "ì•¼ê²½" : ["ì•¼ê²½", "ë°¤ì— ê°€ê¸° ì¢‹ì€", "ë¶ˆë¹› ì˜ˆìœ", "ì•¼ê²½ ëª…ì†Œ", "ì•¼ê²½ ê°ìƒ", "ì•¼ê²½ ìŠ¤íŒŸ"],
    "ì´ë™ê´€ê´‘" : ["ì°¨ëŸ‰ íˆ¬ì–´", "ì‹œí‹° íˆ¬ì–´", "ì´ë™í•˜ë©´ì„œ", "íˆ¬ì–´"],
    "ê³µì›" : ["ê³µì›"],
    "ë„ì‹¬ê³µì›" : ["ë„ì‹¬ê³µì›", "ë„ì‹œì™€ ê³µì›ì„ í•¨ê»˜"],
    "ë¬¸í™”ê±°ë¦¬" : ["ì „í†µ ìˆëŠ” ê±°ë¦¬", "ì˜ˆìˆ  ê±°ë¦¬", "ê°ì„± ê³¨ëª©", "ë¬¸í™” ê±°ë¦¬", "ê³¨ëª©ê¸¸", "ë¶„ìœ„ê¸° ìˆëŠ” ê±°ë¦¬"],
    "í˜¸ìˆ˜" : ["í˜¸ìˆ˜", "í˜¸ìˆ˜ ë·° ì¢‹ì€", "ë¬¼ê°€ ê·¼ì²˜ ì¡°ìš©í•œ ë°"],
    "íœ´ì–‘ì§€" : ["íœ´ì‹", "íœ´ì–‘ì§€", "ì‰¬ëŠ” ê³³", "ì¡°ìš©í•œ íœ´ì–‘ì§€"],
    "ì„±" : ["ì„±"],
    "ê´€ëŒì°¨" : ["ê´€ëŒì°¨", "í•˜ëŠ˜ì—ì„œ"],
    "í…Œë§ˆì „ì‹œ" : ["íŠ¹ì • ì£¼ì œ ì „ì‹œ", "ì²´í—˜í˜• ì „ì‹œ", "ì´ìƒ‰ ì „ì‹œ"],
    "ê°•" : ["ê°•", "ê°•ë³€ ë·°"],
    "ê²½ê¸°ì¥" : ["ì¶•êµ¬ì¥", "ê²½ê¸°ì¥", "ì‘ì›"],
    "ì‚¬ì›" : ["ì‚¬ì°°", "ì‚¬ì›", "ë¶ˆìƒ"],
    "ì‹œì¥" : ["ì‹œì¥", "ê¸¸ê±°ë¦¬ ìŒì‹"],
    "ì•¼ì‹œì¥" : ["ì•¼ì‹œì¥", "ë°¤ì— ì—¬ëŠ” ì‹œì¥", "ë°¤ì— ë¨¹ê±°ë¦¬ ë§ì€ ë°", "í¬ì¥ë§ˆì°¨ ê±°ë¦¬", "ë°¤ ë¶„ìœ„ê¸° ì¢‹ì€ ì‹œì¥"],
    "ë™ë¬¼ì›" : ["ë™ë¬¼ì›", "ë™ë¬¼"],    
    "ê¸°ì°¨" : ["ê¸°ì°¨", "ì—´ì°¨", "ê´€ê´‘ì—´ì°¨"],
    "í•­êµ¬" : ["í•­êµ¬ ë„ì‹œ", "í•­êµ¬", "í•­êµ¬ í’ê²½", "í•­êµ¬ ë§ˆì„"],
    "ê²¨ìš¸ìŠ¤í¬ì¸ " : ["ìŠ¤í‚¤", "ìŠ¤ë…¸ë³´ë“œ", "ê²¨ìš¸ ì•¡í‹°ë¹„í‹°", "ê²¨ìš¸ ìŠ¤í¬ì¸ ", "ì„¤ê²½ ë³´ë©´ì„œ ìŠ¤í¬ì¸ "],
    "ì‹ë¬¼ì›" : ["ì‹ë¬¼ì›", "ì‹ë¬¼ êµ¬ê²½"],
    "ì¼€ì´ë¸”ì¹´" : ["ì¼€ì´ë¸”ì¹´"],
    "í•´ë³€" : ["ë°”ë‹¤", "í•´ë³€", "ëª¨ë˜ì‚¬ì¥", "ëª¨ë˜", "íŒŒë„", "í•´ìˆ˜ìš•ì¥"],
    "í…Œë§ˆíŒŒí¬" : ["ë†€ì´ê³µì›", "í…Œë§ˆíŒŒí¬", "ë†€ì´í„°", "ì–´íŠ¸ë™ì…˜", "ë†€ì´ê¸°êµ¬"],
    "íŠ¸ë ˆí‚¹" : ["íŠ¸ë ˆí‚¹", "ì‚° ë”°ë¼ ê±·ê¸°", "ìì—° ì† ê±·ê¸°"],
    "ì„¬" : ["ì¡°ìš©í•œ ì„¬ ë§ˆì„", "ì„¬"],
    "ë¯¸ì‹" : ["ë¯¸ì‹", "ë§›ìˆëŠ”", "í˜„ì§€ ìŒì‹", "ë¨¹ê±°ë¦¬ íˆ¬ì–´", "ë§›ì§‘"],
    "ë²„ìŠ¤" : ["ë²„ìŠ¤"],
    "ê¸°ë…ê´€" : ["ê¸°ë…ê´€"],
    "ì‹ ì‚¬" : ["ì‹ ì‚¬", "í† ë¦¬ì´"]    
}
intent_to_category = {k: [k] for k in intent_keywords.keys()}
category_mapping = {k: k for k in intent_keywords.keys()}

emotion_to_category_boost = {
    "ì‹ ë‚¨": ["í…Œë§ˆíŒŒí¬", "í•´ì–‘ì²´í—˜", "ë¯¸ì‹", "ë¬¸í™”ê±°ë¦¬", "ì•¼ì‹œì¥", "ì›Œí„°íŒŒí¬"],
    "ê¸°ëŒ€ê°": ["ëœë“œë§ˆí¬","ì „ë§", "ë¬¸í™”ì²´í—˜", "ì´ë™ê´€ê´‘", "í¬í† ì¡´", "ê³µì—°"],
    "í¸ì•ˆí•¨": ["ìì—°", "ì‚°ì±…", "ê³µì›", "í•´ë³€", "í˜¸ìˆ˜", "ì‹ë¬¼ì›", "ë„ì‹¬ê³µì›"],
    "ì•ˆì •": ["íœ´ì–‘ì§€", "í˜¸ìˆ˜", "ì„±ë‹¹", "ë¯¸ìˆ ê´€", "ì˜ˆìˆ ê°ìƒ"],
    "ê°íƒ„": ["ëœë“œë§ˆí¬", "ì „ë§", "ì•¼ê²½", "ì˜ˆìˆ ê°ìƒ", "ì—­ì‚¬", "ì¢…êµ", "í¬í† ì¡´"],
    "í˜¼ë€íšŒë³µ": ["ì¢…êµ", "ë„ì‹¬ê³µì›", "ë¯¸ìˆ ê´€", "ì‚°ì±…", "íŠ¸ë ˆí‚¹"],
    "ê°ì •ì „í™˜": ["í…Œë§ˆíŒŒí¬", "ë™ë¬¼ì›", "ìˆ˜ì¡±ê´€", "ë¬¸í™”ì²´í—˜", "ì‡¼í•‘", "ë¯¸ì‹"],
    "ìœ„ë¡œ": ["ìì—°", "í˜¸ìˆ˜", "ë™ë¬¼ì›", "íœ´ì–‘ì§€", "ì„±ë‹¹"],
    "ë¶€ì •": ["ìì—°", "ê³µì›", "ì„¬"]
}

# ---------------------ì•ˆë‚´ë¬¸êµ¬ ë§¤í•‘ --------------------
theme_ui_map = {
    "ìì—°/í’ê²½ ê°ìƒí˜•": ("íë§ ì—¬í–‰ì§€ ğŸ§˜", "ìì—°ê³¼ í’ê²½ ì†ì—ì„œ í¸ì•ˆí•´ì§€ëŠ” ì¡°ìš©í•œ íœ´ì‹"),
    "ê°€ì¡±/ì²´í—˜ íˆ¬ì–´í˜•": ("ì²´í—˜ ì—¬í–‰ì§€ ğŸ¢", "ì´ìƒ‰ì ì¸ í™œë™ìœ¼ë¡œ ì¦ê¸°ëŠ” ìƒìƒí•œ ì „í™˜"),
    "ì‡¼í•‘/ê±°ë¦¬ ì²´í—˜í˜•": ("ì‡¼í•‘ ì—¬í–‰ì§€ ğŸ›", "ì„¤ë ˜ ê°€ë“í•œ ê±°ë¦¬ì—ì„œ í˜„ì§€ì˜ ìƒ‰ì„ ë‹´ì€ ì¦ê±°ì›€"),
    "ë°•ë¬¼ê´€/ë¬¸í™” ê°ìƒí˜•": ("ë¬¸í™” ì—¬í–‰ì§€ ğŸ¨", "ì˜ˆìˆ ê³¼ ì „í†µì´ ì‚´ì•„ìˆëŠ” ê³µê°„ì—ì„œ ëŠë¼ëŠ” ê°ë™"),
    "ëœë“œë§ˆí¬/ì¢…êµ ê±´ì¶•í˜•": ("ëª…ì†Œ ì—¬í–‰ì§€ ğŸ›", "ê°íƒ„ì„ ë¶€ë¥´ëŠ” í’ê²½ê³¼ í•¨ê»˜ ë„ì‹œì˜ ìƒì§•ì„ ë§Œë‚˜ë‹¤"),
}
ui_to_theme_map = {v[0]: k for k, v in theme_ui_map.items()}

theme_opening_lines = {
    "íë§ ì—¬í–‰ì§€ ğŸ§˜": "ì—¬ìœ ì™€ ìì—°ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” â€˜íë§ ì—¬í–‰ì§€â€™ {}ê³³ì„ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì²´í—˜ ì—¬í–‰ì§€ ğŸ¢": "ëª¸ê³¼ ë§ˆìŒì´ ë“¤ëœ¨ëŠ” â€˜ì²´í—˜ ì—¬í–‰ì§€â€™ {}ê³³ì„ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ë¬¸í™” ì—¬í–‰ì§€ ğŸ¨": "ì˜ˆìˆ ê³¼ ì´ì•¼ê¸°ê°€ ìˆëŠ” â€˜ë¬¸í™” ì—¬í–‰ì§€â€™ {}ê³³ì„ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì‡¼í•‘ ì—¬í–‰ì§€ ğŸ›": "í˜„ì§€ ë¨¹ê±°ë¦¬ê°€ ê°€ë“í•œ â€˜ì‡¼í•‘ ì—¬í–‰ì§€â€™ {}ê³³ì„ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ëª…ì†Œ ì—¬í–‰ì§€ ğŸ›": "ë¬¸í™”ì™€ ìƒì§•ì´ ê¹ƒë“  â€˜ëª…ì†Œ ì—¬í–‰ì§€â€™ {}ê³³ì„ ì¶”ì²œë“œë¦´ê²Œìš”.",
}

intent_opening_lines = {
    "ì‡¼í•‘": "ğŸ› í˜„ì§€ ë¬¼í’ˆì´ ê°€ë“í•œ ì‡¼í•‘í•˜ê¸° ì¢‹ì€ ì—¬í–‰ì§€ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì‹¤ë‚´": "ğŸ  ë¹„ ì˜¤ëŠ” ë‚ ì—ë„ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ì‹¤ë‚´ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ê°€ì¡±": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ê°€ì¡± ëª¨ë‘ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ë”°ëœ»í•œ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ì›Œí„°íŒŒí¬": "ğŸ’¦ ì‹ ë‚˜ê²Œ ë¬¼ë†€ì´í•  ìˆ˜ ìˆëŠ” ì›Œí„°íŒŒí¬ ëª…ì†Œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ìì—°": "ğŸŒ¿ í‘¸ë¥´ë¥¸ í’ê²½ê³¼ ìì—°ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ì „ë§": "ğŸ”­ í•œëˆˆì— ë·°ê°€ ë“¤ì–´ì˜¤ëŠ” ì „ë§ ì¢‹ì€ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "í¬í† ì¡´": "ğŸ“¸ ì¸ìƒìƒ· ë‚¨ê¸°ê¸° ì¢‹ì€ í¬í†  ìŠ¤íŒŸ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "í•´ì–‘ì²´í—˜": "ğŸ¤¿ ìŠ¤ë…¸í´ë§, ë‹¤ì´ë¹™ ë“± í•´ì–‘ ì•¡í‹°ë¹„í‹° ëª…ì†Œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ìˆ˜ì¡±ê´€": "ğŸ  í•´ì–‘ ìƒë¬¼ì„ ê°€ê¹Œì´ì„œ ë§Œë‚  ìˆ˜ ìˆëŠ” ìˆ˜ì¡±ê´€ì„ ì†Œê°œí• ê²Œìš”.",
    "ì¢…êµ": "ğŸ• ì„±ìŠ¤ëŸ¬ìš´ ë¶„ìœ„ê¸°ë¥¼ ëŠë‚„ ìˆ˜ ìˆëŠ” ì¢…êµ ëª…ì†Œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì„±ë‹¹": "â›ª ì—­ì‚¬ ê¹Šì€ ì•„ë¦„ë‹¤ìš´ ì„±ë‹¹ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì˜ˆì‹ì¥": "ğŸ’’ ë¡œë§¨í‹±í•œ ì›¨ë”© ì´¬ì˜ì§€ì™€ ì˜ˆì‹ì¥ì„ ì†Œê°œí• ê²Œìš”.",
    "ì»¤í”Œ": "ğŸ’• ë°ì´íŠ¸í•˜ê¸° ì¢‹ì€ ë¡œë§¨í‹±í•œ ì»¤í”Œ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ëœë“œë§ˆí¬": "ğŸ“ ë„ì‹œë¥¼ ëŒ€í‘œí•˜ëŠ” ìƒì§•ì ì¸ ëª…ì†Œë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ì—­ì‚¬": "ğŸ“œ ê³¼ê±°ì˜ ì´ì•¼ê¸°ê°€ ë‹´ê¸´ ì—­ì‚¬ì ì¸ ì¥ì†Œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ê¶ì „": "ğŸ° í™”ë ¤í•œ ê¶ì „ê³¼ ì™•ì‹¤ì˜ í”ì ì´ ë‹´ê¸´ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ë¬¸í™”ì²´í—˜": "ğŸ§µ ì „í†µì„ ì§ì ‘ ì²´í—˜í•  ìˆ˜ ìˆëŠ” ë¬¸í™” ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ë°•ë¬¼ê´€": "ğŸ› ì§€ì‹ì„ ìŒ“ì„ ìˆ˜ ìˆëŠ” ë°•ë¬¼ê´€ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì˜ˆìˆ ê°ìƒ": "ğŸ¨ ê°ì„±ê³¼ ì°½ì˜ë ¥ì´ ìê·¹ë˜ëŠ” ì˜ˆìˆ  ê³µê°„ì„ ì†Œê°œí• ê²Œìš”.",
    "ì²´í—˜ê´€": "ğŸ§ª ì§ì ‘ ë°°ìš°ê³  ì¦ê¸¸ ìˆ˜ ìˆëŠ” ì²´í—˜í˜• ê³µê°„ì„ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ê´‘ì¥": "ğŸ§­ í˜„ì§€ ë¶„ìœ„ê¸°ë¥¼ ëŠë‚„ ìˆ˜ ìˆëŠ” í™œê¸°ì°¬ ê´‘ì¥ì„ ì†Œê°œí• ê²Œìš”.",
    "ì‚°ì±…": "ğŸš¶ ì¡°ìš©íˆ ê±·ê¸° ì¢‹ì€ ì‚°ì±… ì½”ìŠ¤ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ë¯¸ìˆ ê´€": "ğŸ–¼ ì „ì‹œíšŒì™€ ê·¸ë¦¼ ê°ìƒì´ ê°€ëŠ¥í•œ ë¯¸ìˆ ê´€ ëª…ì†Œë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ê³µì—°": "ğŸ­ ê³µì—°ê³¼ ë¬´ëŒ€ë¥¼ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ê·¹ì¥ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ìœ ëŒì„ ": "ğŸš¢ ë°”ë‹¤ ìœ„ì—ì„œ ì¦ê¸°ëŠ” ìœ ëŒì„  ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ì•¼ê²½": "ğŸŒƒ ë°¤í•˜ëŠ˜ê³¼ ë¶ˆë¹›ì´ ì•„ë¦„ë‹¤ìš´ ì•¼ê²½ ëª…ì†Œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì´ë™ê´€ê´‘": "ğŸšŒ ì°¨ëŸ‰ìœ¼ë¡œ í¸í•˜ê²Œ ì´ë™í•˜ë©° ì¦ê¸°ëŠ” íˆ¬ì–´ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ê³µì›": "ğŸŒ³ ìì—°ì„ í’ˆì€ ì—¬ìœ ë¡œìš´ ê³µì›ì„ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ë„ì‹¬ê³µì›": "ğŸ ë„ì‹œ ì† ì‰¼í‘œê°€ ë˜ì–´ì¤„ ë„ì‹¬ê³µì›ì„ ì†Œê°œí• ê²Œìš”.",
    "ë¬¸í™”ê±°ë¦¬": "ğŸ§± ì˜ˆìˆ ê³¼ ì „í†µì´ ê¹ƒë“  ê°ì„± ê³¨ëª©ê¸¸ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "í˜¸ìˆ˜": "ğŸ ì”ì”í•œ ë¬¼ê²°ì´ ìˆëŠ” íë§ í˜¸ìˆ˜ ëª…ì†Œë¥¼ ì†Œê°œí• ê²Œìš”.",
    "íœ´ì–‘ì§€": "ğŸŒ´ ì¡°ìš©íˆ ì‰¬ì–´ê°€ê¸° ì¢‹ì€ íœ´ì–‘ì§€ ê³³ì„ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì„±": "ğŸ¯ ì¤‘ì„¸ ë¶„ìœ„ê¸°ë¥¼ ëŠë‚„ ìˆ˜ ìˆëŠ” ê³ í’ìŠ¤ëŸ¬ìš´ ì„±ì„ ì†Œê°œí• ê²Œìš”.",
    "ê´€ëŒì°¨": "ğŸ¡ í•˜ëŠ˜ ìœ„ì—ì„œ í’ê²½ì„ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ê´€ëŒì°¨ ëª…ì†Œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "í…Œë§ˆì „ì‹œ": "ğŸ–¼ ì´ìƒ‰ì ì¸ í…Œë§ˆ ì „ì‹œë¡œ ê°€ë“í•œ ê³µê°„ì„ ì†Œê°œí• ê²Œìš”.",
    "ê°•": "ğŸŒŠ ë¬¼ê¸¸ ë”°ë¼ ì—¬ìœ ë¥¼ ëŠë‚„ ìˆ˜ ìˆëŠ” ê°•ë³€ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ê²½ê¸°ì¥": "âš½ ìŠ¤í¬ì¸ ì˜ ì—´ê¸°ê°€ ê°€ë“í•œ ê²½ê¸°ì¥ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ì‚¬ì›": "ğŸ›• ê³ ìš”í•œ ë¶„ìœ„ê¸°ì˜ ì „í†µ ì‚¬ì°° ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì‹œì¥": "ğŸ§º í˜„ì§€ ë¶„ìœ„ê¸°ê°€ ì‚´ì•„ìˆëŠ” ì „í†µ ì‹œì¥ì„ ì†Œê°œí• ê²Œìš”.",
    "ì•¼ì‹œì¥": "ğŸŒ™ ë°¤ì´ ë” ì•„ë¦„ë‹¤ìš´ ì•¼ì‹œì¥ ë¨¹ê±°ë¦¬ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ë™ë¬¼ì›": "ğŸ¦ ê·€ì—¬ìš´ ë™ë¬¼ë“¤ì„ ë§Œë‚  ìˆ˜ ìˆëŠ” ë™ë¬¼ì› ëª…ì†Œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ê¸°ì°¨": "ğŸš‚ ëŠë¦¿í•˜ê²Œ ë‹¬ë¦¬ëŠ” ê¸°ì°¨ì™€ í•¨ê»˜í•˜ëŠ” ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "í•­êµ¬": "âš“ ë°”ë‹¤ì™€ ë„ì‹œê°€ ë§Œë‚˜ëŠ” í•­êµ¬ í’ê²½ ëª…ì†Œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ê²¨ìš¸ìŠ¤í¬ì¸ ": "â›· ìŠ¤í‚¤ì™€ ë³´ë“œë¡œ ê²¨ìš¸ì„ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ìŠ¤í¬ì¸  ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ì‹ë¬¼ì›": "ğŸŒº í‘¸ë¥´ë¥¸ ì‹ë¬¼ì´ ê°€ë“í•œ ì‹ë¬¼ì› íë§ ê³µê°„ì„ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì¼€ì´ë¸”ì¹´": "ğŸš¡ í•˜ëŠ˜ì—ì„œ í’ê²½ì„ ê°ìƒí•  ìˆ˜ ìˆëŠ” ì¼€ì´ë¸”ì¹´ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "í•´ë³€": "ğŸ– í–‡ì‚´ê³¼ íŒŒë„ê°€ ë°˜ê¸°ëŠ” í•´ë³€ ëª…ì†Œë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "í…Œë§ˆíŒŒí¬": "ğŸ  ì–´íŠ¸ë™ì…˜ê³¼ ì¬ë¯¸ê°€ ê°€ë“í•œ í…Œë§ˆíŒŒí¬ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "íŠ¸ë ˆí‚¹": "ğŸ¥¾ ìì—° ì†ì„ ê±·ëŠ” íŠ¸ë ˆí‚¹ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì„¬": "ğŸ ë°”ë‹¤ ìœ„ ê³ ìš”í•œ ì„¬ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ë¯¸ì‹": "ğŸ½ í˜„ì§€ ìŒì‹ì„ ë§›ë³¼ ìˆ˜ ìˆëŠ” ë¯¸ì‹ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ë²„ìŠ¤": "ğŸšŒ ì´ë™ì´ í¸ë¦¬í•œ ë²„ìŠ¤ íˆ¬ì–´ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
    "ê¸°ë…ê´€": "ğŸ—¿ ê¸°ì–µì„ ê°„ì§í•œ ê¸°ë…ê´€ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
    "ì‹ ì‚¬": "â›© ì‹ ë¹„ë¡­ê³  í‰ì˜¨í•œ ë¶„ìœ„ê¸°ì˜ ì‹ ì‚¬ ì—¬í–‰ì§€ë¥¼ ì†Œê°œí• ê²Œìš”.",
}
#--------------------íŒ¨í‚¤ì§€ ë¬¸êµ¬---------------------------
theme_title_phrases = {
    "íë§ ì—¬í–‰ì§€ ğŸ§˜": [
        "ì™„ì „ íœ´ì‹ íë§", "ì¡°ìš©í•œ ì‰¼í‘œ ê°ì„±", "ë§ˆìŒ íšŒë³µ ì—¬ì •", "ì—¬ìœ  ê°€ë“ ì¹˜ìœ ", "ì¬ì¶©ì „ ìŠ¬ë¡œìš° ë¼ì´í”„",
        "í˜¼ìë§Œì˜ ìœ„ë¡œ ì—¬í–‰", "ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ íë§", "í¸ì•ˆí•œ í•˜ë£¨ ì‰¼", "ë¬´ë¦¬ ì—†ëŠ” íœ´ì‹ ì½”ìŠ¤", "ê³ ìš”í•œ ìì—° ì† ì—¬ìœ "
    ],
    "ì²´í—˜ ì—¬í–‰ì§€ ğŸ¢": [
        "ì•¡í‹°ë¹„í‹° ê°€ë“ ì²´í—˜", "ì „í†µ+í˜„ì§€í™œë™ ì¦ê¸°ê¸°", "ì˜¤ê°ë§Œì¡± í˜„ì§€ ì²´í—˜", "ìƒìƒí•œ íˆ¬ì–´ ì¤‘ì‹¬", "ë¡œì»¬ ë¼ì´í”„ ëª°ì…í˜•",
        "ì´ìƒ‰ í™œë™ íƒí—˜ ì—¬í–‰", "ë‹¤ì±„ë¡œìš´ ì²´í—˜ ë‚˜ë“¤ì´", "ì§ì ‘ í•´ë³´ëŠ” ì²´í—˜ ìœ„ì£¼", "ì°¸ì—¬í˜• íˆ¬ì–´ ì—¬í–‰", "ì´ìƒ‰ì ì¸ í•˜ë£¨ ì²´í—˜"
    ],
    "ë¬¸í™” ì—¬í–‰ì§€ ğŸ¨": [
        "ê°ì„± ê¹Šì€ ë¬¸í™” ì‚°ì±…", "ì˜ˆìˆ +ì—­ì‚¬ ê°ìƒ íˆ¬ì–´", "ì „í†µê³¼ í˜„ëŒ€ì˜ ì¡°í™”", "ë¯¸ìˆ ê³¼ ê³µì—° íƒë°©í˜•", "ê³ ìš”í•œ ë°•ë¬¼ê´€ ì—¬í–‰",
        "ìœ ì‚° ë”°ë¼ ê±·ëŠ” ê¸¸", "ëª…í™” ë”°ë¼ ê°€ëŠ” ì—¬í–‰", "ì¸ë¬¸í•™ ê°ì„± ë¬¸í™” ì½”ìŠ¤", "ì˜ˆìˆ í’ˆê³¼ í•¨ê»˜í•˜ëŠ” ì—¬ì •", "ì „ì‹œ+ì˜ˆìˆ  ê°ìƒ ì¤‘ì‹¬"
    ],
    "ì‡¼í•‘ ì—¬í–‰ì§€ ğŸ›": [
        "í˜„ì§€ ê°ì„± ì‡¼í•‘", "íŠ¸ë Œë”” ë§ˆì¼“ íƒë°©", "ë¨¹ê±°ë¦¬+ê¸°ë…í’ˆ ê±°ë¦¬íˆ¬ì–´", "í•«í”Œ ë§ˆì¼“ ë‚˜ë“¤ì´", "ë¡œì»¬ ë¸Œëœë“œ ì‡¼í•‘",
        "ì‹œì¥ ê³¨ëª© ì²´í—˜í˜• ì‡¼í•‘", "ê°ì„± ì†Œí’ˆ ìˆ˜ì§‘ ì—¬í–‰", "ì‹¤ì†í˜• ì‡¼í•‘ íƒë°©", "ë“í…œ íˆ¬ì–´ ì—¬í–‰", "ì¦ê±°ìš´ ê±°ë¦¬ íƒë°©"
    ],
    "ëª…ì†Œ ì—¬í–‰ì§€ ğŸ›": [
        "ëœë“œë§ˆí¬ ì§‘ì¤‘ íˆ¬ì–´", "ìœ ëª… ëª…ì†Œ í•µì‹¬ì¼ì •", "ë„ì‹œ ìƒì§• ëª…ì†Œì—¬í–‰", "ì‚¬ì§„ ë§›ì§‘ ìŠ¤íŒŸ íˆ¬ì–´", "ëŒ€í‘œ ì¥ì†Œ ì™„ì „ì •ë³µ",
        "ìƒì§•ì  ì¥ì†Œ ë”°ë¼ê°€ê¸°", "ìœ ì +ê±´ì¶• í•µì‹¬ ì½”ìŠ¤", "ë„ì‹œ í•œëˆˆì— ë³´ê¸° ì—¬í–‰", "ë² ìŠ¤íŠ¸ ëª…ì†Œ ëª°ì•„ë³´ê¸°", "ìƒì§• ëª…ì†Œ ìŠ¤íƒ¬í”„ íˆ¬ì–´"
    ]
}

feature_phrase_map = {
    frozenset(["ìˆ™ì†Œ", "ì¼ì •"]): [
        "í¸ì•ˆí•œ ìˆ™ì†Œì™€ ì•Œì°¬ ì¼ì •ì´ ë‹ë³´ì´ëŠ” ì—¬í–‰ì´ì—ìš”", "ì¡°ìš©í•œ ìˆ™ì†Œì—ì„œ ì‹œì‘í•´ ì¼ì •ê¹Œì§€ ì—¬ìœ ë¡­ê²Œ ì¦ê²¨ë³´ì„¸ìš”",
        "ìˆ™ì†Œì™€ ì¼ì • ëª¨ë‘ ê· í˜•ì¡íŒ ì™„ë²½í•œ ì—¬í–‰ì´ ê¸°ë‹¤ë ¤ìš”"
    ],
    frozenset(["ìˆ™ì†Œ", "ê°€ì´ë“œ"]): [
        "ì¹œì ˆí•œ ê°€ì´ë“œì™€ í¸ì•ˆí•œ ìˆ™ì†Œê°€ ì—¬í–‰ì˜ í’ˆê²©ì„ ë†’ì—¬ì¤˜ìš”", "ë¯¿ìŒì§í•œ ê°€ì´ë“œì™€ í‘¹ ì‰´ ìˆ˜ ìˆëŠ” ìˆ™ì†Œê°€ ì¡°í™”ë¥¼ ì´ë¤„ìš”",
        "ì¢‹ì€ ìˆ™ì†Œì™€ ì„¸ì‹¬í•œ ê°€ì´ë“œê°€ ìŠì§€ ëª»í•  ì¶”ì–µì„ ë§Œë“¤ì–´ì¤˜ìš”"
    ],
    frozenset(["ìˆ™ì†Œ", "ì‹ì‚¬"]): [
        "ë§›ìˆëŠ” ìŒì‹ê³¼ í¬ê·¼í•œ ìˆ™ì†Œê°€ í•˜ë£¨ë¥¼ ì™„ë²½í•˜ê²Œ ë§ˆë¬´ë¦¬í•´ì¤˜ìš”", "í¸ì•ˆí•œ ìˆ™ì†Œì—ì„œ íœ´ì‹í•˜ê³ , ì…ë§› ë‹ìš°ëŠ” ì‹ì‚¬ê¹Œì§€ ì¦ê²¨ë³´ì„¸ìš”",
        "ìˆ™ì†Œì™€ ì‹ì‚¬ ëª¨ë‘ ê¸°ëŒ€ ì´ìƒ! í•˜ë£¨ê°€ ì¦ê±°ì›Œì§€ëŠ” ì¡°í•©ì´ì—ìš”"
    ],
    frozenset(["ìˆ™ì†Œ", "ê°€ì„±ë¹„"]): [
        "í•©ë¦¬ì ì¸ ê°€ê²©ì— ìˆ™ì†Œ í€„ë¦¬í‹°ê¹Œì§€ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì—¬í–‰ì´ì—ìš”", "ê°€ì„±ë¹„ ì¢‹ê³  í¸í•œ ìˆ™ì†Œ ë•ë¶„ì— ì—¬ìœ ë¡œìš´ ì—¬í–‰ì´ ê°€ëŠ¥í•´ìš”",
        "ê°€ì„±ë¹„ì™€ ìˆ™ì†Œ í€„ë¦¬í‹° ëª¨ë‘ ì¡ì€ ìµœê³ ì˜ ì„ íƒì´ì—ìš”"
    ],
    frozenset(["ìˆ™ì†Œ", "ì´ë™ìˆ˜ë‹¨"]): [
        "ìˆ™ì†Œì™€ êµí†µ ëª¨ë‘ ê±±ì • ì—†ëŠ” í¸ì•ˆí•œ ì—¬í–‰ ì½”ìŠ¤ì˜ˆìš”", "í¸í•œ ìˆ™ì†Œì™€ í¸ë¦¬í•œ ì´ë™ìœ¼ë¡œ í”¼ë¡œ ì—†ì´ ì¦ê²¨ìš”",
        "ìˆ™ì†Œ ìœ„ì¹˜ë„ ì¢‹ê³  ì´ë™ë„ í¸í•´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ì—†ëŠ” ì¼ì •ì´ì—ìš”"
    ],
    frozenset(["ì¼ì •", "ê°€ì´ë“œ"]): [
        "ê³„íšì ì¸ ì¼ì •ê³¼ ì„¸ì‹¬í•œ ê°€ì´ë“œê°€ í•¨ê»˜í•˜ëŠ” ë§Œì¡±ë„ ë†’ì€ ì—¬í–‰ì´ì—ìš”", "ì¹œì ˆí•œ ê°€ì´ë“œì˜ ì•ˆë‚´ë¡œ ì¼ì •ì´ í›¨ì”¬ ì•Œì°¨ê³  í¸ì•ˆí•´ìš”",
        "ì‹œê°„ ë‚­ë¹„ ì—†ì´ ë˜‘ë˜‘í•˜ê²Œ ì¦ê¸°ëŠ” ì¼ì •, ë¯¿ìŒì§í•œ ê°€ì´ë“œê¹Œì§€ ì™„ë²½í•´ìš”"
    ],
    frozenset(["ì¼ì •", "ì‹ì‚¬"]): [
        "ì‹œê°„ ì•Œì°¨ê³  ì‹ì‚¬ê¹Œì§€ ë§Œì¡±ë„ ë†’ì€ êµ¬ì„±ì´ì—ìš”", "ì¼ì •ì´ ì§œì„ìƒˆ ìˆê³ , ì‹ì‚¬ë„ êµ°ë”ë”ê¸° ì—†ì–´ìš”",
        "ì‹ì‚¬ ì‹œê°„ì´ ê¸°ë‹¤ë ¤ì§ˆ ë§Œí¼ êµ¬ì„± ì¢‹ì€ ì¼ì •ì´ì—ìš”"
    ],
    frozenset(["ì¼ì •", "ê°€ì„±ë¹„"]): [
        "ì•Œì°¬ ì¼ì •ê³¼ ê°€ì„±ë¹„ ë†’ì€ êµ¬ì„±ìœ¼ë¡œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì—¬í–‰ì´ì—ìš”", "ì‹œê°„ë„ ëˆë„ ì•„ë¼ëŠ” ì‹¤ì† ìˆëŠ” ì¼ì •ì´ì—ìš”",
        "ì§€ë£¨í•˜ì§€ ì•Šì€ ì•Œì°¬ ì¼ì •ê³¼ ì°©í•œ ê°€ê²©, ê°€ì„±ë¹„ ìµœê³ ì—ìš”"
    ],
    frozenset(["ì¼ì •", "ì´ë™ìˆ˜ë‹¨"]): [
        "íš¨ìœ¨ì ì¸ ì¼ì •ê³¼ í¸ë¦¬í•œ ì´ë™ìœ¼ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ ì—†ëŠ” ì—¬í–‰ì´ì—ìš”", "ì´ë™ì´ í¸í•´ì„œ ì¼ì •ì´ ë” ì¦ê²ê³  ì—¬ìœ ë¡œì›Œìš”",
        "ë¶€ë“œëŸ¬ìš´ ì´ë™ ë£¨íŠ¸ì™€ ì•Œì°¬ ì¼ì •ì˜ ì¡°í™”ê°€ ì¸ìƒ ê¹Šì–´ìš”"
    ],
    frozenset(["ê°€ì´ë“œ", "ì‹ì‚¬"]): [
        "ì¹œì ˆí•œ ê°€ì´ë“œì™€ ë§›ìˆëŠ” ìŒì‹ì´ ê°ë™ì„ ë”í•´ì¤˜ìš”", "ê°€ì´ë“œì˜ ì„¤ëª…ê³¼ ë§›ìˆëŠ” ìŒì‹ìœ¼ë¡œ ì—¬í–‰ì´ í’ì„±í•´ì ¸ìš”",
        "ì…ë„ ë§ˆìŒë„ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì‹ì‚¬ì™€ ê°€ì´ë“œ ì¡°í•©ì´ì—ìš”"
    ],
    frozenset(["ê°€ì´ë“œ", "ê°€ì„±ë¹„"]): [
        "ì„¸ì‹¬í•œ ì•ˆë‚´ì™€ ì¢‹ì€ êµ¬ì„±, ê°€ê²©ê¹Œì§€ ì¡ì€ ì‹¤ì† ìˆëŠ” ì—¬í–‰ì´ì—ìš”", "ì €ë ´í•œ ê°€ê²©ì—ë„ í›Œë¥­í•œ ê°€ì´ë“œë¥¼ ë§Œë‚  ìˆ˜ ìˆì–´ìš”",
        "ê°€ê²© ëŒ€ë¹„ ì„œë¹„ìŠ¤ ìµœê³ ! ê°€ì´ë“œ ë•ì— ë” ì•Œì°¨ê³  ì™„ë²½í•´ìš”"
    ],
    frozenset(["ê°€ì´ë“œ", "ì´ë™ìˆ˜ë‹¨"]): [
        "ë¯¿ìŒì§í•œ ê°€ì´ë“œì™€ ì¾Œì í•œ ì´ë™ìˆ˜ë‹¨ìœ¼ë¡œ í¸ì•ˆí•œ ì—¬í–‰ì´ì—ìš”", "ê°€ì´ë“œì˜ ë™ì„  ì„¤ê³„ê°€ ì´ë™ì„ í›¨ì”¬ íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜ìš”",
        "í¸ì•ˆí•œ ì´ë™ê³¼ ë…¸ë ¨í•œ ê°€ì´ë“œì˜ ì¡°í•©ìœ¼ë¡œ ê¸´ ì—¬ì •ë„ ë“ ë“ í•´ìš”"
    ],
    frozenset(["ì‹ì‚¬", "ê°€ì„±ë¹„"]): [
        "ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì‹ì‚¬ì™€ ê°€ê²©ê¹Œì§€ ì°©í•œ ì—¬í–‰ ì½”ìŠ¤ì˜ˆìš”", "ìŒì‹ í€„ë¦¬í‹°ì™€ ê°€ì„±ë¹„ê¹Œì§€ ì¡ì€ íŒ¨í‚¤ì§€ êµ¬ì„±ì´ì—ìš”",
        "ì‹ì‚¬ë„ í‘¸ì§í•˜ê³  ê°€ê²©ë„ í•©ë¦¬ì ì¸ ìµœê³ ì˜ êµ¬ì„±!"
    ],
    frozenset(["ì‹ì‚¬", "ì´ë™ìˆ˜ë‹¨"]): [
        "ì—¬ìœ ë¡œìš´ ì´ë™ê³¼ ë“ ë“ í•œ ì‹ì‚¬ë¡œ ì—¬í–‰ì´ ë”ìš± ì¦ê±°ì›Œìš”", "í¸ì•ˆí•œ ë²„ìŠ¤ íƒ€ê³  ê°€ëŠ” ê¸¸ë§ˆë‹¤ ë§›ì§‘ íˆ¬ì–´ ê°™ì€ ê²½í—˜ì´ì—ìš”",
        "ì¹œì ˆí•œ ì´ë™ê¸°ì‚¬ë‹˜ê³¼ ë§›ìˆëŠ” ì‹ì‚¬ê°€ ì¡°í™”ë¡œìš´ íŒ¨í‚¤ì§€ì—ìš”"
    ],
    frozenset(["ê°€ì„±ë¹„", "ì´ë™ìˆ˜ë‹¨"]): [
        "êµí†µ í¸ì˜ì„±ê³¼ ê°€ê²© ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì‹¤ì† ì—¬í–‰ì´ì—ìš”", "ê°€ê²© ì°©í•˜ê³  ì´ë™ë„ í¸ë¦¬í•´ì„œ ë¶€ë‹´ ì—†ì´ ê°€ê¸° ì¢‹ì€ íŒ¨í‚¤ì§€ì—ìš”",
        "ê°€ë³ê²Œ ë– ë‚˜ê¸° ì¢‹ì€ ê°€ì„±ë¹„+êµí†µ ì¡°í•©ì´ì—ìš”"
    ]
}
# -------------------- ì±—ë´‡ ì—°ë™ --------------------
def get_intent_intro_message(intent: str) -> str:
    intent_opening_texts = {
    "ì‡¼í•‘":"íŠ¹ë³„í•œ ê¸°ë…í’ˆê³¼ í˜„ì§€ì˜ ë§¤ë ¥ì„ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì‹¤ë‚´": "ë‚ ì”¨ì™€ ìƒê´€ì—†ì´ ì•Œì°¨ê²Œ ì—¬í–‰ì„ ì¦ê¸°ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ê°€ì¡±": "ê°€ì¡±ê³¼ í•¨ê»˜ ì†Œì¤‘í•œ ì¶”ì–µì„ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì›Œí„°íŒŒí¬": "ë¬¼ë†€ì´ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë‚ ë¦¬ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
    "ìì—°": "ìì—° ì†ì—ì„œ íë§í•˜ê³  ì‹¶ì€ ë§ˆìŒì´ ëŠê»´ì ¸ìš”.",
    "ì „ë§": "íƒ íŠ¸ì¸ í’ê²½ì„ ë°”ë¼ë³´ë©° ì—¬ìœ ë¥¼ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "í¬í† ì¡´": "ìŠì§€ ëª»í•  ìˆœê°„ì„ ì‚¬ì§„ìœ¼ë¡œ ë‚¨ê¸°ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "í•´ì–‘ì²´í—˜": "ë°”ë‹¤ ì† ì„¸ìƒì„ ê°€ê¹Œì´ì—ì„œ ëŠë¼ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
    "ìˆ˜ì¡±ê´€": "í•´ì–‘ ìƒë¬¼ì„ ì§ì ‘ ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
    "ì¢…êµ": "ë§ˆìŒì˜ í‰í™”ë¥¼ ì°¾ê³  ì‹¶ì€ ì—¬í–‰ì„ ì›í•˜ì‹œë‚˜ìš”?",
    "ì„±ë‹¹": "ì•„ë¦„ë‹¤ìš´ ê±´ì¶•ê³¼ ê³ ìš”í•¨ì„ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì˜ˆì‹ì¥": "íŠ¹ë³„í•œ ìˆœê°„ì„ ë¡œë§¨í‹±í•˜ê²Œ ë‚¨ê¸°ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì»¤í”Œ": "ë‘˜ë§Œì˜ ë¡œë§¨í‹±í•œ ì‹œê°„ì„ ë³´ë‚´ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ëœë“œë§ˆí¬": "ë„ì‹œì˜ ëŒ€í‘œ ëª…ì†Œì—ì„œ ê·¸ ì§€ì—­ì˜ ë§¤ë ¥ì„ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì—­ì‚¬": "ê³¼ê±°ì˜ í”ì  ì†ì—ì„œ ê¹Šì€ ì´ì•¼ê¸°ë¥¼ ëŠë¼ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
    "ê¶ì „": "ì™•ì‹¤ì˜ í™”ë ¤í•¨ì„ ê²½í—˜í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ë¬¸í™”ì²´í—˜": "ì „í†µ ë¬¸í™”ë¥¼ ì§ì ‘ ì²´í—˜í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
    "ë°•ë¬¼ê´€": "ìƒˆë¡œìš´ ì§€ì‹ê³¼ í¥ë¯¸ë¡œìš´ ì „ì‹œë¥¼ ê²½í—˜í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì˜ˆìˆ ê°ìƒ": "ê°ì„±ê³¼ ì°½ì˜ë ¥ì„ ìê·¹í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì²´í—˜ê´€": "ì§ì ‘ í•´ë³´ëŠ” ì²´í—˜ìœ¼ë¡œ ìƒìƒí•œ ì—¬í–‰ì„ ì›í•˜ì‹œë‚˜ìš”?",
    "ê´‘ì¥": "í˜„ì§€ ë¶„ìœ„ê¸°ë¥¼ ì§ì ‘ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì‚°ì±…": "ì—¬ìœ ë¡­ê²Œ ê±¸ìœ¼ë©° ìƒê° ì •ë¦¬í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ë¯¸ìˆ ê´€": "ì˜ˆìˆ ì‘í’ˆ ì†ì—ì„œ ì—¬ìœ ì™€ ì˜ê°ì„ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”",
    "ê³µì—°": "ìƒìƒí•œ ë¬´ëŒ€ì™€ ê°ë™ì„ ì§ì ‘ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ìœ ëŒì„ ": "ë°”ë‹¤ ìœ„ì—ì„œ ë‚­ë§Œì ì¸ ì‹œê°„ì„ ë³´ë‚´ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì•¼ê²½": "ë‚®ë³´ë‹¤ ì•„ë¦„ë‹¤ìš´ ë°¤ í’ê²½ì„ ê°ìƒí•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì´ë™ê´€ê´‘": "í¸í•˜ê²Œ ì´ë™í•˜ë©´ì„œ ë‹¤ì–‘í•œ ëª…ì†Œë¥¼ ë³´ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ê³µì›": "ì ì‹œ ì¼ìƒì„ ë²—ì–´ë‚˜ ì—¬ìœ ë¥¼ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ë„ì‹¬ê³µì›": "ë„ì‹œ ì†ì—ì„œ ì ê¹ì˜ ì‰¼ì„ ì›í•˜ì‹œë‚˜ìš”?",
    "ë¬¸í™”ê±°ë¦¬": "ê±·ê¸°ë§Œ í•´ë„ ê°ì„±ì´ ì±„ì›Œì§€ëŠ” ê³¨ëª©ì„ ì›í•˜ì‹œë‚˜ìš”?",
    "í˜¸ìˆ˜": "ì”ì”í•œ í’ê²½ ì†ì—ì„œ ë§ˆìŒì˜ í‰í™”ë¥¼ ì°¾ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "íœ´ì–‘ì§€": "ì•„ë¬´ ìƒê° ì—†ì´ ì‰¬ì–´ê°€ê³  ì‹¶ì€ ìˆœê°„ì´ì‹œêµ°ìš”.",
    "ì„±": "ì¤‘ì„¸ ê°ì„±ì˜ ê³ í’ìŠ¤ëŸ¬ì›€ì„ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ê´€ëŒì°¨": "ë†’ì€ ê³³ì—ì„œ ìƒ‰ë‹¤ë¥¸ í’ê²½ì„ ë³´ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "í…Œë§ˆì „ì‹œ": "ë…íŠ¹í•œ ì½˜í…ì¸ ë¡œ ìƒˆë¡œìš´ ìê·¹ì„ ì›í•˜ì‹œë‚˜ìš”?",
    "ê°•": "ë¬¼ì†Œë¦¬ë¥¼ ë“¤ìœ¼ë©° ì—¬ìœ ë¥¼ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ê²½ê¸°ì¥": "í˜„ì¥ì˜ ì—´ê¸°ì™€ ë°•ì§„ê°ì„ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì‚¬ì›": "ê³ ìš”í•œ ê³µê°„ì—ì„œ ë§ˆìŒì„ ê°€ë¼ì•‰íˆê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì‹œì¥": "í˜„ì§€ì˜ ì§„ì§œ ì¼ìƒì„ ê²½í—˜í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì•¼ì‹œì¥": "ë°¤ì´ ë” ë§¤ë ¥ì ì¸ ì—¬í–‰ì„ ê¸°ëŒ€í•˜ê³  ê³„ì‹œêµ°ìš”.",
    "ë™ë¬¼ì›": "ê·€ì—¬ìš´ ì¹œêµ¬ë“¤ì„ ë§Œë‚˜ë©° íë§í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ê¸°ì°¨": "ì²œì²œíˆ ì´ë™í•˜ë©° í’ê²½ì„ ì¦ê¸°ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "í•­êµ¬": "ë°”ë‹·ë°”ëŒê³¼ í•¨ê»˜ ë‚­ë§Œì„ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ê²¨ìš¸ìŠ¤í¬ì¸ ": "ëˆˆ ìœ„ì—ì„œ ì§œë¦¿í•œ í™œë™ì„ ì›í•˜ì‹œë‚˜ìš”?",
    "ì‹ë¬¼ì›": "í”¼í†¤ì¹˜ë“œí–¥ì´ ê°€ë“í•œ ê³µê°„ì—ì„œ í¸ì•ˆí•¨ì„ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì¼€ì´ë¸”ì¹´": "ìƒ‰ë‹¤ë¥¸ ì‹œì•¼ë¡œ í’ê²½ì„ ë°”ë¼ë³´ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "í•´ë³€": "í–‡ì‚´ê³¼ ë°”ë‹¤ë¥¼ í•¨ê»˜ ì¦ê¸°ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "í…Œë§ˆíŒŒí¬": "í•˜ë£¨ì¢…ì¼ ì›ƒê³  ë›°ì–´ë†€ê³  ì‹¶ì€ ê¸°ë¶„ì´ì‹ ê°€ìš”?",
    "íŠ¸ë ˆí‚¹": "ìì—° ì†ì—ì„œ ëª¸ê³¼ ë§ˆìŒì„ ê±·ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ì„¬": "ë³µì¡í•¨ì—ì„œ ë²—ì–´ë‚˜ ê³ ìš”í•¨ì„ ì°¾ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ë¯¸ì‹": "ìƒˆë¡œìš´ ë§›ìœ¼ë¡œ ì—¬í–‰ì˜ ì¦ê±°ì›€ì„ ë”í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ë²„ìŠ¤": "í¸í•˜ê²Œ ë‘˜ëŸ¬ë³´ë©° ì—¬í–‰í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
    "ê¸°ë…ê´€": "ê·¸ ì‹œì ˆì„ ë‹¤ì‹œ ëŠë¼ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
    "ì‹ ì‚¬": "ì‹ ë¹„ë¡­ê³  ì¡°ìš©í•œ ì¥ì†Œë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”.",
    }
    if intent in intent_opening_texts:
        return intent_opening_texts[intent]
    else:
        raise ValueError(f"ì˜ë„ '{intent}'ì— ë§ëŠ” ë¬¸êµ¬ê°€ ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

def determine_weather_description_official(row):
    try:
        rain = float(row["ê°•ìˆ˜ëŸ‰"])
        humidity = float(row["ìŠµë„"])
    except Exception:
        return "ë‚ ì”¨ ì •ë³´ ì—†ìŒ"

    if rain >= 10:
        return "ë¹„ê°€ ë§ì´ ì˜¤ëŠ” ë‚ ì”¨ì˜ˆìš”."
    elif rain >= 3:
        return "ë¹„ê°€ ì˜¤ëŠ” ë‚ ì”¨ì˜ˆìš”."
    elif rain >= 0.5:
        return "ì•½í•œ ë¹„ê°€ ì˜¤ëŠ” ë‚ ì”¨ì˜ˆìš”."
    else:
        if humidity >= 85:
            return "íë¦° ë‚ ì”¨ì˜ˆìš”."
        elif humidity >= 65:
            return "êµ¬ë¦„ì´ ë§ì€ ë‚ ì”¨ì˜ˆìš”."
        else:
            return "ë§‘ì€ ë‚ ì”¨ì˜ˆìš”."

def get_weather_message(city, weather_df, date="2025-06-01"):
    date = pd.to_datetime(date).date()

    # 'ë‚ ì§œ' ì»¬ëŸ¼ì´ datetimeìœ¼ë¡œ ë˜ì–´ìˆìœ¼ë©´ dateë¡œ ë³€í™˜
    if pd.api.types.is_datetime64_any_dtype(weather_df["ë‚ ì§œ"]):
        weather_df["ë‚ ì§œ_ì¼ì"] = weather_df["ë‚ ì§œ"].dt.date
    else:
        weather_df["ë‚ ì§œ_ì¼ì"] = pd.to_datetime(weather_df["ë‚ ì§œ"], errors="coerce").dt.date

    # 2. ì •í™• ì¼ì¹˜ ì‹œë„
    exact_match = weather_df[
        (weather_df["ì—¬í–‰ë„ì‹œ"].str.strip() == city.strip())
        & (weather_df["ë‚ ì§œ_ì¼ì"] == date)
    ]
    if not exact_match.empty:
        row = exact_match.iloc[0]
    else:
        # 3. í¬í•¨ ê²€ìƒ‰ ì‹œë„
        partial_match = weather_df[
            (weather_df["ì—¬í–‰ë„ì‹œ"].str.contains(city, na=False))
            & (weather_df["ë‚ ì§œ_ì¼ì"] == date)
        ]
        if not partial_match.empty:
            row = partial_match.iloc[0]
        else:
            return f"ğŸ“… {city}ì˜ {date} ë‚ ì”¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

    # ìµœê³  ê¸°ì˜¨
    try:
        temp = f"{float(row['ìµœê³ _ê¸°ì˜¨']):.1f}"
        temp_a = f"{float(row['ìµœì €_ê¸°ì˜¨']):.1f}Â°C"
    except Exception:
        temp = "ì •ë³´ ì—†ìŒ"

    # ì„¤ëª…
    desc = determine_weather_description_official(row)

    return f"ğŸ“… {row['ì—¬í–‰ë„ì‹œ']}ì˜ ë‚ ì”¨ëŠ” {temp}/{temp_a}, {desc}"



def generate_intro_message(intent=None, emotion_groups=None, emotion_scores=None, min_emotion_score=15.0):
    from collections import defaultdict
    import random

    emotion_priority = [
        "ê°ì •ì „í™˜", "ìœ„ë¡œ", "í˜¼ë€íšŒë³µ", "ì•ˆì •", "í¸ì•ˆí•¨", "ê°íƒ„", "ì‹ ë‚¨", "ë¶€ì •"
    ]

    emotion_messages = {
        "ì‹ ë‚¨": "ğŸ‰ ì¦ê±°ì›€ì´ ê°€ë“í•œ ì—¬í–‰ì„ ì°¾ê³  ê³„ì‹œëŠ”êµ°ìš”.",
        "í¸ì•ˆí•¨": "ğŸ˜Œ ê³ ìš”í•˜ê³  í¸ì•ˆí•œ ì—¬í–‰ì´ í•„ìš”í•˜ì‹œêµ°ìš”.",
        "ì•ˆì •": "ğŸ•Šï¸ ë§ˆìŒì˜ ì•ˆì •ì„ ì°¾ê³  ì‹¶ìœ¼ì‹ ê°€ ë´ìš”.",
        "ê°íƒ„": "ğŸ˜ ê°ë™ê³¼ ë†€ë¼ì›€ì„ ëŠë¼ê³  ì‹¶ìœ¼ì‹œêµ°ìš”.",
        "í˜¼ë€íšŒë³µ": "ğŸŒ€ ë§ˆìŒì„ ì •ë¦¬í•  ì‹œê°„ì´ í•„ìš”í•˜ì‹ ê°€ ë´ìš”.",
        "ê°ì •ì „í™˜": "ğŸ”„ ê¸°ë¶„ ì „í™˜ì´ í•„ìš”í•œ ìˆœê°„ì´ë„¤ìš”.",
        "ìœ„ë¡œ": "ğŸ¤ ì§€ì¹œ ë§ˆìŒì— ì‘ì€ ìœ„ë¡œê°€ í•„ìš”í•˜ì‹œêµ°ìš”.",
        "ë¶€ì •": "ğŸ˜® ì ì‹œ ë©ˆì¶° ìˆ¨ ëŒë¦´ ì‹œê°„ì´ í•„ìš”í•˜ì‹œêµ°ìš”."
    }

    neutral_messages = [
        "ì§€ê¸ˆ ì´ ìˆœê°„, ì–´ë–¤ ì—¬í–‰ì´ ì–´ìš¸ë¦´ì§€ í•¨ê»˜ ê³ ë¯¼í•´ë´¤ì–´ìš”.",
        "ê¸°ë¶„ ì „í™˜ì´ í•„ìš”í•˜ì‹  ê²ƒ ê°™ì•„ìš”. ì—¬ëŸ¬ ìŠ¤íƒ€ì¼ì˜ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”.",
        "ë”± ë–¨ì–´ì§€ëŠ” ëª©ì ì€ ì—†ì§€ë§Œ, ì–´ë”˜ê°€ ë– ë‚˜ê³  ì‹¶ì„ ë•Œê°€ ìˆì£ .",
        "ì§€ê¸ˆ ë§ˆìŒì— ë§ì„ ìˆ˜ ìˆëŠ” ì—¬í–‰ ìŠ¤íƒ€ì¼ ëª‡ ê°€ì§€ë¥¼ ê³¨ë¼ë´¤ì–´ìš”.",
        "ë‹¤ì–‘í•œ ê°ì •ì„ ë‹´ì„ ìˆ˜ ìˆëŠ” ì—¬í–‰ì§€ë¥¼ ì¤€ë¹„í–ˆì–´ìš”.",
        "ì§€ê¸ˆì˜ ê¸°ë¶„ì— ë§ì¶°, ì–´ìš¸ë¦´ ë§Œí•œ ì—¬í–‰ ìŠ¤íƒ€ì¼ì„ ì œì•ˆë“œë¦´ê²Œìš”."
    ]

    # ğŸ‘‰ ì‚¬ì „ ì˜¤ë²„ë¼ì´ë“œ ê²°ê³¼ ìš°ì„  ì ìš©
    if emotion_groups:
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ê°€ì¥ ë¨¼ì € ë§¤ì¹­ë˜ëŠ” ê°ì • ê·¸ë£¹ ë©”ì‹œì§€ë¥¼ ë¦¬í„´
        for emo in emotion_priority:
            if emo in emotion_groups:
                return emotion_messages.get(emo, random.choice(neutral_messages))

    # ğŸ‘‰ ëª¨ë¸ ê°ì • ì ìˆ˜ ê¸°ë°˜ ì ìš©
    group_scores = defaultdict(float)
    if emotion_scores:
        for klue_label, score in emotion_scores:
            group = klue_label_to_group.get(klue_label)
            if group:
                group_scores[group] = max(group_scores[group], score)

    for emo in emotion_priority:
        if emo in group_scores:
            return emotion_messages.get(emo, random.choice(neutral_messages))

    # ğŸ‘‰ ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ì¤‘ë¦½ ë©”ì‹œì§€
    return random.choice(neutral_messages)

def generate_region_intro(city=None, country=None):# ì¶”ê°€ í•¨############################
    name = city if city else country
    templates = [
        f"âœ¨ ë‚­ë§Œì´ ê°€ë“í•œ {name}ì˜ ë§¤ë ¥ì ì¸ ì—¬í–‰ì§€ë¡œ ì—¬ëŸ¬ë¶„ì„ ì´ˆëŒ€í• ê²Œìš”!",
        f"ğŸŒ {name}ì—ì„œë§Œ ëŠë‚„ ìˆ˜ ìˆëŠ” íŠ¹ë³„í•œ ê°ì„±ê³¼ ìˆœê°„ì„ í•¨ê»˜ ì°¾ì•„ë³¼ê¹Œìš”?",
        f"ğŸ“ ê¸°ì–µì— ì˜¤ë˜ ë‚¨ì„ {name}ì˜ ì•„ë¦„ë‹¤ìš´ ì—¬í–‰ì§€ë“¤ì„ í•˜ë‚˜í•˜ë‚˜ ì†Œê°œí•´ë“œë¦´ê²Œìš”.",
        f"ğŸŒ¿ {name}ì—ì„œë§Œ ë§Œë‚ ìˆ˜ ìˆëŠ” ë§¤ë ¥ ê°€ë“í•œ ì—¬í–‰ì§€ë¥¼ ì—„ì„ í–ˆì–´ìš”.",
        f"ğŸ’ ì¼ìƒ ì† ì‰¼í‘œê°€ í•„ìš”í•œ ì§€ê¸ˆ, {name}ì—ì„œ ì„¤ë ˜ ê°€ë“í•œ ì—¬ì •ì„ ë– ë‚˜ë³´ì„¸ìš”."
    ]
    return random.choice(templates)

def parse_companion_and_age(text):
    companions = None
    age_group = None

    # ì‚¬ìš©ì ì…ë ¥ âœ ì‹¤ì œ ì»¬ëŸ¼ëª… ë§¤í•‘
    companion_map = {
        "í˜¼ì": "ë‚˜í˜¼ì",
        "ë‚˜í˜¼ì": "ë‚˜í˜¼ì",
        "ì¹œêµ¬": "ì¹œêµ¬ë“¤ê³¼",
        "ì¹œêµ¬ë“¤": "ì¹œêµ¬ë“¤ê³¼",
        "ì»¤í”Œ": "ì»¤í”Œ",
        "ì—°ì¸": "ì»¤í”Œ",
        "ê°€ì¡±": "ê°€ì¡±ì—¬í–‰",
        "ë‹¨ì²´": "ë‹¨ì²´ì—¬í–‰"
    }

    # ë‚˜ì´ëŒ€ ë§¤í•‘ (CSV ì»¬ëŸ¼ ê·¸ëŒ€ë¡œ)
    age_map = {
        "20ëŒ€": "20ëŒ€",
        "30ëŒ€": "30ëŒ€",
        "40ëŒ€": "40ëŒ€",
        "50ëŒ€": "50ëŒ€",
        "60ëŒ€": "60ëŒ€ ì´ìƒ ",       
        "60ëŒ€ ì´ìƒ": "60ëŒ€ ì´ìƒ "
    }

    text = text.strip()

    # ë™í–‰ íŒŒì‹±
    for k, mapped in companion_map.items():
        if k in text:
            companions = mapped
            break

    # ë‚˜ì´ëŒ€ íŒŒì‹±
    for k, mapped in age_map.items():
        if k in text:
            age_group = mapped
            break

    # ìˆ«ìë§Œ ì…ë ¥í–ˆì„ ë•Œ ì²˜ë¦¬
    if age_group is None:
        if "20" in text:
            age_group = "20ëŒ€"
        elif "30" in text:
            age_group = "30ëŒ€"
        elif "40" in text:
            age_group = "40ëŒ€"
        elif "50" in text:
            age_group = "50ëŒ€"
        elif "60" in text:
            age_group = "60ëŒ€ ì´ìƒ "

    return companions, age_group


#------------------------- ìˆ˜ì •
def make_companion_age_message(companions, age_group):
    companion_friendly = {
        "í˜¼ì": "í˜¼ì",
        "ë‚˜í˜¼ì": "í˜¼ì",
        "ì¹œêµ¬": "ì¹œêµ¬ë¶„ë“¤ê³¼",
        "ì¹œêµ¬ë“¤ê³¼": "ì¹œêµ¬ë¶„ë“¤ê³¼",
        "ì»¤í”Œ": "ì—°ì¸ê³¼",
        "ê°€ì¡±ì—¬í–‰": "ê°€ì¡±ë¶„ë“¤ê³¼",
        "ê°€ì¡±": "ê°€ì¡±ë¶„ë“¤ê³¼",
        "ë‹¨ì²´ì—¬í–‰": "ë‹¨ì²´ë¡œ",
        "ë‹¨ì²´": "ë‹¨ì²´ë¡œ"
    }

    age_friendly = {
        "20ëŒ€": "20ëŒ€",
        "30ëŒ€": "30ëŒ€",
        "40ëŒ€": "40ëŒ€",
        "50ëŒ€": "50ëŒ€",
        "60ëŒ€ ì´ìƒ": "60ëŒ€ ì´ìƒ",
        "60ëŒ€": "60ëŒ€ ì´ìƒ"
    }
    
    # âœ” ë¦¬ìŠ¤íŠ¸ â†’ ì²« í•­ëª©(ëŒ€í‘œê°’) ë˜ëŠ” None
    def to_friendly(terms, mapping):
        if not terms:
            return []
        if not isinstance(terms, list):
            terms = [terms]
        return [mapping[t] for t in terms if t in mapping]
    
    friendly_ages = to_friendly(age_group, age_friendly)
    friendly_companions = to_friendly(companions, companion_friendly)

    age_text = ", ".join(friendly_ages) + " ì—¬í–‰ê°" if friendly_ages else ""
    companion_text = ", ".join(friendly_companions)

    if friendly_ages and friendly_companions:
        return f"ğŸ’¡{age_text} {companion_text} ì—¬í–‰í•˜ì‹œëŠ” ë¶„ë“¤ê»˜ íŠ¹íˆ ì¸ê¸° ìˆëŠ” íŒ¨í‚¤ì§€ì˜ˆìš”."
    elif friendly_ages:
        return f"ğŸ’¡{age_text} ë¶„ë“¤ê»˜ ì¸ê¸° ìˆëŠ” íŒ¨í‚¤ì§€ì˜ˆìš”."
    elif friendly_companions:
        return f"ğŸ’¡{companion_text} ì—¬í–‰í•˜ì‹œëŠ” ë¶„ë“¤ê»˜ íŠ¹íˆ ì¸ê¸° ìˆëŠ” íŒ¨í‚¤ì§€ì˜ˆìš”."
    else:
        return ""

#------------------------- ê°™ì€ ê·¸ë£¹ì— 2ê°œì´ìƒ ì„ íƒì´ ê°€ëŠ¥í•˜ë„ë¡ ë¡œì§ ìˆ˜ì •
def filter_packages_by_companion_age(package_df, companions=None, age_group=None, city=None, top_n=5):
    # ì‚¬ìš©ì ì…ë ¥ âœ ì‹¤ì œ ì»¬ëŸ¼ëª… ë§¤í•‘
    companion_map = {
            "í˜¼ì": "ë‚˜í˜¼ì",
            "ë‚˜í˜¼ì": "ë‚˜í˜¼ì",
            "ì¹œêµ¬": "ì¹œêµ¬ë“¤ê³¼",
            "ì¹œêµ¬ë“¤": "ì¹œêµ¬ë“¤ê³¼",
            "ì»¤í”Œ": "ì»¤í”Œ",
            "ì—°ì¸": "ì»¤í”Œ",
            "ê°€ì¡±": "ê°€ì¡±ì—¬í–‰",
            "ë‹¨ì²´": "ë‹¨ì²´ì—¬í–‰"
        }

    # ë‚˜ì´ëŒ€ ë§¤í•‘ (CSV ì»¬ëŸ¼ ê·¸ëŒ€ë¡œ)
    age_map = {
            "20ëŒ€": "20ëŒ€",
            "30ëŒ€": "30ëŒ€",
            "40ëŒ€": "40ëŒ€",
            "50ëŒ€": "50ëŒ€",
            "60ëŒ€": "60ëŒ€ ì´ìƒ ",       
            "60ëŒ€ ì´ìƒ": "60ëŒ€ ì´ìƒ"
        }

    # companions, age_group â†’ ë¦¬ìŠ¤íŠ¸ë¡œ í†µì¼
    comp_list = companions if isinstance(companions, list) else ([companions] if companions else [])
    age_list  = age_group  if isinstance(age_group, list)  else ([age_group]  if age_group  else [])

    companions = [companion_map.get(c) for c in comp_list if companion_map.get(c) in package_df.columns]
    age_group  = [age_map.get(a) for a in age_list  if age_map.get(a) in package_df.columns]

    df = package_df.copy()

    # city ì»¬ëŸ¼ ìˆìœ¼ë©´ í•„í„°
    if city and "ì—¬í–‰ë„ì‹œ" in df.columns:
        df = df[df["ì—¬í–‰ë„ì‹œ"].str.contains(city, na=False)]

    # ì¡°ê±´1: ë™í–‰+ì—°ë ¹
    if companions and age_group:
        mask = (df[companions].sum(axis=1) > 0) & (df[age_group].sum(axis=1) > 0)
        both = df[mask].copy()
        if len(both) >= top_n:
            both["ì ìˆ˜í•©"] = both[companions + age_group].sum(axis=1)
            return both.sort_values("ì ìˆ˜í•©", ascending=False).head(top_n)
        
    # ì¡°ê±´2: ì—°ë ¹ë§Œ
    if age_group:
        age_only = df[df[age_group].sum(axis=1) > 0].copy()
        if len(age_only) >= top_n:
            age_only["ì ìˆ˜"] = age_only[age_group].sum(axis=1)
            return age_only.sort_values("ì ìˆ˜", ascending=False).head(top_n)
        
    # ì¡°ê±´3: ë™í–‰ë§Œ
    if companions:
        comp_only = df[df[companions].sum(axis=1) > 0].copy()
        if len(comp_only) >= top_n:
            comp_only["ì ìˆ˜"] = comp_only[companions].sum(axis=1)
            return comp_only.sort_values("ì ìˆ˜", ascending=False).head(top_n)
        
    # ì¡°ê±´4: ì•„ë¬´ ì¡°ê±´ë„ ì—†ê±°ë‚˜ ê°œìˆ˜ ë¶€ì¡±
    return df.sample(n=min(top_n, len(df)))

# -------------------- í•µì‹¬ í•¨ìˆ˜ --------------------
def get_highlight_message(selected_place, travel_df, external_score_df, festival_df):
    import random
    from datetime import datetime

    # ë©”ì‹œì§€ í’€
    messages_pool = {
        "festival_score": [
            "ğŸ‰ ì§€ê¸ˆ {city}ì—ì„œëŠ” '{festival_name}'ì´ ì§„í–‰ ì¤‘ì´ì—ìš”!",
            "ğŸŠ '{festival_name}' ì¶•ì œê°€ ì—´ë¦¬ê³  ìˆì–´ìš”! ë†“ì¹˜ì§€ ë§ˆì„¸ìš”."
        ],
        "cost_score": [
            "ğŸ’¸ ì—¬í–‰ ë¹„ìš©ì´ ì €ë ´í•œ í¸ì´ë¼ ë¶€ë‹´ ì—†ì´ ë‹¤ë…€ì˜¬ ìˆ˜ ìˆì–´ìš”.",
            "ğŸ’° ì˜ˆìƒ ê²½ë¹„ê°€ ë‚®ì•„ì„œ ê°€ì„±ë¹„ ì¢‹ì€ ì—¬í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        ],
        "norm_fx": [
            "ğŸ’± í™˜ìœ¨ì´ ë–¨ì–´ì ¸ì„œ í™˜ì „í•˜ê¸° ì¢‹ì€ ì‹œê¸°ì˜ˆìš”.",
            "ğŸ’µ í™˜ìœ¨ì´ ì•ˆì •ì ì´ë¼ ì—¬í–‰ ê²½ë¹„ê°€ ì ˆì•½ë©ë‹ˆë‹¤.",
            "1,000ì›ìœ¼ë¡œ ë” ë§ì€ ê¸ˆì•¡ì„ í™˜ì „í•  ìˆ˜ ìˆì–´ìš”!"
        ],
        "norm_cpi": [
            "ğŸ› í˜„ì§€ ë¬¼ê°€ê°€ ì €ë ´í•´ì„œ ì—¬í–‰ ê²½ë¹„ê°€ í•©ë¦¬ì ì´ì—ìš”.",
            "â˜• ì¹´í˜, ì‹ì‚¬, ì‡¼í•‘ê¹Œì§€ ë¶€ë‹´ì´ ëœí•´ìš”.",
            "í‰ê· ë³´ë‹¤ ë‚®ì€ ë¬¼ê°€ ë•ë¶„ì— ì—¬ìœ ë¡œìš´ ì—¬í–‰ì´ ê°€ëŠ¥í•´ìš”."
        ],
        "íŠ¸ë Œë“œê¸‰ìƒìŠ¹": [
            "ğŸ“ˆ ìµœê·¼ ê²€ìƒ‰ëŸ‰ì´ ê¸‰ë“±í–ˆì–´ìš”. ìš”ì¦˜ ëœ¨ëŠ” ì—¬í–‰ì§€ì˜ˆìš”!",
            "ğŸ”¥ ì§€ê¸ˆ ë§ì€ ì‚¬ëŒë“¤ì´ ì´ê³³ì„ ê²€ìƒ‰í•˜ê³  ìˆì–´ìš”!"
        ],
        "trend_score": [
            "â­ ì—¬í–‰ê°ë“¤ì—ê²Œ ê¾¸ì¤€íˆ ì‚¬ë‘ë°›ê³  ìˆëŠ” ê³³ì´ì—ìš”.",
            "âœ¨ ì–¸ì œ ê°€ë„ ë§Œì¡±ë„ê°€ ë†’ì€ ì¸ê¸° ì—¬í–‰ì§€ì˜ˆìš”.",
            "ğŸ’– ì§€ê¸ˆë„ ë§ì€ ì‚¬ëŒë“¤ì´ ì°¾ëŠ” ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì—¬í–‰ì§€ì˜ˆìš”."
        ]
    }

    # ğŸ¯ ì¶•ì œëª… ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
    def get_festival_name(city, festival_df):
        today = datetime.today().date()
        matches = festival_df[festival_df["ì—¬í–‰ë„ì‹œ"] == city]
        if matches.empty:
            return "í˜„ì§€ ì¶•ì œ"
        matches = matches.copy()
        try:
            matches["ì‹œì‘ì¼"] = pd.to_datetime(matches["ì‹œì‘ì¼"], errors="coerce").dt.date
            matches["ì¢…ë£Œì¼"] = pd.to_datetime(matches["ì¢…ë£Œì¼"], errors="coerce").dt.date
        except Exception:
            return "í˜„ì§€ ì¶•ì œ"
        # ì§„í–‰ì¤‘
        ongoing = matches[(matches["ì‹œì‘ì¼"] <= today) & (matches["ì¢…ë£Œì¼"] >= today)]
        if not ongoing.empty:
            return random.choice(ongoing["ì¶•ì œëª…"].dropna().tolist())
        # ë‹¤ê°€ì˜¤ëŠ”
        upcoming = matches[matches["ì‹œì‘ì¼"] > today].sort_values("ì‹œì‘ì¼")
        if not upcoming.empty:
            return upcoming.iloc[0]["ì¶•ì œëª…"]
        return "í˜„ì§€ ì¶•ì œ"

    # ğŸŒ ì—¬í–‰ì§€ì— í•´ë‹¹í•˜ëŠ” ë„ì‹œ/ë‚˜ë¼ ê°€ì ¸ì˜¤ê¸°
    place_row = travel_df[travel_df["ì—¬í–‰ì§€"] == selected_place]
    if place_row.empty:
        return None

    place_row = place_row.iloc[0]
    city = place_row["ì—¬í–‰ë„ì‹œ"]
    country = place_row["ì—¬í–‰ë‚˜ë¼"]

    # ì™¸ë¶€ìš”ì¸ ë°ì´í„°ì—ì„œ í•´ë‹¹ ë„ì‹œ/ë‚˜ë¼ ì°¾ê¸°
    external_row = external_score_df[
        (external_score_df["ì—¬í–‰ë„ì‹œ"] == city) &
        (external_score_df["ì—¬í–‰ë‚˜ë¼"] == country)
    ]
    if external_row.empty:
        return None

    external_row = external_row.iloc[0]

    # ì¡°ê±´ë³„ ë§Œì¡± ì—¬ë¶€ ì²´í¬
    highlight_candidates = []

    if external_row.get("festival_score", 0) >= 2:
        festival_name = get_festival_name(city, festival_df)
        if festival_name != 'í˜„ì§€ ì¶•ì œ':
            msg = random.choice(messages_pool["festival_score"]).format(city=city, festival_name=festival_name)
            highlight_candidates.append(msg)

    if external_row.get("cost_score", 0) == 10:
        highlight_candidates.append(random.choice(messages_pool["cost_score"]))

    if external_row.get("norm_fx", 99) < 1.0:
        highlight_candidates.append(random.choice(messages_pool["norm_fx"]))

    if external_row.get("norm_cpi", 99) < 1.0:
        highlight_candidates.append(random.choice(messages_pool["norm_cpi"]))

    if str(external_row.get("íŠ¸ë Œë“œê¸‰ìƒìŠ¹", "")).strip() == "ê¸‰ìƒìŠ¹":
        highlight_candidates.append(random.choice(messages_pool["íŠ¸ë Œë“œê¸‰ìƒìŠ¹"]))

    if external_row.get("trend_score", 0) >= 6.0:
        highlight_candidates.append(random.choice(messages_pool["trend_score"]))

    if not highlight_candidates:
        fallback_messages = [
        "ğŸŒ¿ ì¼ìƒì„ ë²—ì–´ë‚˜ ìƒˆë¡œìš´ ê²½í—˜ì„ ë§Œë“¤ì–´ì£¼ëŠ”, {city}ë¡œ ë– ë‚˜ë³´ì„¸ìš”.",
        "ğŸˆ ëšœë ·í•œ ëª©ì  ì—†ì´ë„ ì¢‹ì€ ê¸°ì–µë§Œ ë‚¨ê²Œ í•´ì£¼ëŠ”, {city}ì˜ˆìš”.",
        "ğŸŒ¸ ë§¤ë ¥ì´ í˜ëŸ¬ë„˜ì¹˜ëŠ” ë„ì‹œ, {city}ì—ì„œ í–‰ë³µí•œ ì‹œê°„ì„ ë³´ë‚´ë³´ì„¸ìš”."
        ]
        return random.choice(fallback_messages).format(city=city)

    # ëœë¤ 1ê°œë§Œ ì„ íƒ
    return random.choice(highlight_candidates)
    
def apply_weighted_score_random_top(df, top_n=50, sample_k=3):
    # ğŸ›¡ ì›ë³¸ ë°±ì—…: ì™¸ë¶€ ì ìˆ˜ ì—†ëŠ” ê²ƒë„ í¬í•¨ëœ ì „ì²´ df
    original_df = df.drop_duplicates(subset=["ì—¬í–‰ì§€"]).copy()

    # ì™¸ë¶€ ì ìˆ˜ì™€ ë³‘í•©
    merged = pd.merge(df, external_score_df, on=["ì—¬í–‰ë„ì‹œ", "ì—¬í–‰ë‚˜ë¼"], how="left")
    merged["ì¢…í•©ì ìˆ˜"] = merged["ì¢…í•©ì ìˆ˜"].fillna(0)

    # ìƒìœ„ ì ìˆ˜ ì •ë ¬
    ranked = merged.sort_values(by="ì¢…í•©ì ìˆ˜", ascending=False).drop_duplicates(subset=["ì—¬í–‰ì§€"])

    # ìµœìƒìœ„ top_n ì¤‘ sample_kê°œ ì„ íƒ
    top_df = ranked.head(top_n)
    top_count = min(sample_k, len(top_df))
    sampled_top = top_df.sample(n=top_count, random_state=random.randint(1, 9999))

    # ë¶€ì¡±í•˜ë©´ bottomì—ì„œ ì±„ìš°ê¸°
    bottom_pool = ranked.iloc[top_n:]
    needed = max(0, 3 - len(sampled_top))
    if needed > 0 and not bottom_pool.empty:
        sampled_bottom = bottom_pool.sample(n=min(needed, len(bottom_pool)), random_state=random.randint(1, 9999))
        final_df = pd.concat([sampled_top, sampled_bottom], ignore_index=True)
    else:
        final_df = sampled_top

    # ğŸ”’ ìµœì¢… ë³´ì™„: ì™¸ë¶€ ì ìˆ˜ ì—†ë˜ ì›ë³¸ dfì—ì„œ ë¬´ì¡°ê±´ 3ê°œ ì±„ìš°ê¸°
    if len(final_df) < 3:
        additional = original_df[~original_df["ì—¬í–‰ì§€"].isin(final_df["ì—¬í–‰ì§€"])]
        if not additional.empty:
            fill_df = additional.sample(n=min(3 - len(final_df), len(additional)), random_state=random.randint(1, 9999))
            final_df = pd.concat([final_df, fill_df], ignore_index=True)

    return final_df
    
def apply_weighted_score_filter(df, top_n=50, sample_k=3):
    return apply_weighted_score_random_top(df, top_n=top_n, sample_k=sample_k)

def override_emotion_if_needed(text):
    for keyword, (emotion_label, emotion_group) in emotion_override_dict.items():
        if keyword in text:
            return [(emotion_label, 50.0)], [emotion_group]
    return None
    
def analyze_emotion(user_input):
    sentiment_model = load_sentiment_model()
    tokenizer = load_tokenizer()
    override = override_emotion_if_needed(user_input)
    if override:
        return override
    inputs = tokenizer(user_input, return_tensors="pt", truncation=True)
    with torch.no_grad():
        probs = F.softmax(sentiment_model(**inputs).logits, dim=1)[0]
    top_indices = torch.topk(probs, k=5).indices.tolist()
    top_emotions = [(klue_emotions[i], float(probs[i]) * 100) for i in top_indices]
    top_emotion_groups = list(dict.fromkeys([klue_to_general[i] for i in top_indices if probs[i] > 0.05]))
    return top_emotions, top_emotion_groups

def detect_intent(user_input):
    force_map = {
        "ìˆ˜ì¡±ê´€": "ìˆ˜ì¡±ê´€", "ì•„ì¿ ì•„ë¦¬ì›€":"ìˆ˜ì¡±ê´€", "ì›Œí„°íŒŒí¬": "ì›Œí„°íŒŒí¬", "ì‡¼í•‘":"ì‡¼í•‘", "ì»¤í”Œ":"ì»¤í”Œ", "ì‹¤ë‚´":"ì‹¤ë‚´", "ê°€ì¡±":"ê°€ì¡±", "ì‚°ì±…":"ì‚°ì±…",
        "ì „ë§":"ì „ë§",  "í•´ì–‘ ì²´í—˜":"í•´ì–‘ì²´í—˜", "ì¢…êµ":"ì¢…êµ", "ì„±ë‹¹":"ì„±ë‹¹", "ì›¨ë”©":"ì˜ˆì‹ì¥", "ì—­ì‚¬":"ì—­ì‚¬", "ìì—°":"ìì—°",
        "ê¶ì „":"ê¶ì „", "ë¬¸í™” ì²´í—˜": "ë¬¸í™”ì²´í—˜", "ë°•ë¬¼ê´€":"ë°•ë¬¼ê´€", "ì˜ˆìˆ  ì‘í’ˆ":"ì˜ˆìˆ ê°ìƒ", "ê³¼í•™ê´€":"ì²´í—˜ê´€", "ê´‘ì¥":"ê´‘ì¥", "ë¯¸ìˆ ê´€":"ë¯¸ìˆ ê´€",
        "ê³µì—°":"ê³µì—°", "ìœ ëŒì„ ":"ìœ ëŒì„ ", "ì•¼ê²½":"ì•¼ê²½", "í˜¸ìˆ˜":"í˜¸ìˆ˜", "íœ´ì–‘ì§€":"íœ´ì–‘ì§€","ê´€ëŒì°¨":"ê´€ëŒì°¨", "ê°•":"ê°•",
        "ê²½ê¸°ì¥":"ê²½ê¸°ì¥", "ì‚¬ì›":"ì‚¬ì›", "ì‹œì¥":"ì‹œì¥", "ì•¼ì‹œì¥":"ì•¼ì‹œì¥", "ë™ë¬¼ì›":"ë™ë¬¼ì›", "ê¸°ì°¨":"ê¸°ì°¨", "í•­êµ¬":"í•­êµ¬", "ê²¨ìš¸ ìŠ¤í¬ì¸ ":"ê²¨ìš¸ìŠ¤í¬ì¸ ",
        "ì‹ë¬¼ì›":"ì‹ë¬¼ì›", "ì¼€ì´ë¸”ì¹´":"ì¼€ì´ë¸”ì¹´", "í•´ë³€":"í•´ë³€", "ë°”ë‹¤":"í•´ë³€", "í…Œë§ˆíŒŒí¬":"í…Œë§ˆíŒŒí¬", "íŠ¸ë ˆí‚¹":"íŠ¸ë ˆí‚¹", "ì„¬":"ì„¬", "ë§›ìˆëŠ”":"ë¯¸ì‹", 
        "ë²„ìŠ¤":"ë²„ìŠ¤", "ê¸°ë…ê´€":"ê¸°ë…ê´€", "ì‹ ì‚¬":"ì‹ ì‚¬", 'ë°”ë‹¤':'í•´ë³€', 'ì¸ìƒìƒ·':'í¬í† ì¡´','ë¨¹ë°©':'ë¯¸ì‹','ì†Œí’ˆ':'ì‡¼í•‘','ë°”ë‹·ê°€':'í•´ë³€','ì„œí•‘':'í•´ì–‘ì²´í—˜',
        'ì¼ëª°':'ì „ë§','ë¡œë§¨í‹±':'ì»¤í”Œ','ë¸Œëœë“œìƒµ':'ì‡¼í•‘','ì•„ìš¸ë ›':'ì‡¼í•‘','ë¹„ì¹˜':'í•´ë³€','ê³ ì„±':'ì„±','ê³ ê¶':'ê¶ì „','ë¬¸í™”ê±°ë¦¬':'ë¬¸í™”ê±°ë¦¬','ì „í†µë§ˆì„':'ë¬¸í™”ì²´í—˜',
        'ê³¤ëŒë¼':'ì¼€ì´ë¸”ì¹´','ìŠ¤ì¹´ì´ë¼ì¸':'ì „ë§','íë§':'íœ´ì–‘ì§€', 'ë¯¸ì‹':'ì‡¼í•‘', 'ë¬¸í™”':'ë¬¸í™”ì²´í—˜', 'ê±·ê¸°':'ì‚°ì±…'
    }
    for keyword, mapped_intent in force_map.items():
        if keyword in user_input:
            return mapped_intent, 1.0
    phrases, labels = [], []
    for intent, keywords in intent_keywords.items():
        for word in keywords:
            phrases.append(word)
            labels.append(intent)

    sbert_model = load_sbert_model()
    input_emb = sbert_model.encode(user_input, convert_to_tensor=True)
    phrase_embs = sbert_model.encode(phrases, convert_to_tensor=True)
    sims = util.cos_sim(input_emb, phrase_embs)[0]
    max_idx = torch.argmax(sims).item()
    return labels[max_idx], float(sims[max_idx])

def extract_themes(emotion_groups, intent, force_mode=False):
    scores = defaultdict(float)
    if force_mode:
        mapped = category_mapping.get(intent)
        if mapped:
            scores[mapped] += 1.0
        return list(scores.keys())[:3]
    for group in emotion_groups:
        for cat in emotion_to_category_boost.get(group, []):
            mapped = category_mapping.get(cat)
            if mapped:
                scores[mapped] += 1.0
    mapped = category_mapping.get(intent)
    if mapped:
        scores[mapped] += 1.5
    ranked = sorted(scores.items(), key=lambda x: -x[1])
    
    return [x[0] for x in ranked[:3]]


def recommend_places_by_theme(theme, country_filter=None, city_filter=None):
    today = datetime.today().date()
    
    # 1. í…Œë§ˆ í•„í„°ë§
    df = travel_df[travel_df['ì˜ë„í…Œë§ˆëª…'].str.contains(theme, na=False)].drop_duplicates(subset=["ì—¬í–‰ì§€"])

    # 2. êµ­ê°€/ë„ì‹œ í•„í„°ë§
    if city_filter:
        df = df[df["ì—¬í–‰ë„ì‹œ"].str.contains(city_filter)]
    if country_filter:
        df = df[df["ì—¬í–‰ë‚˜ë¼"].str.contains(country_filter)]

    # 3. ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ DF ë¦¬í„´
    if df.empty:
        df = pd.DataFrame(columns=travel_df.columns)  # ë¹ˆ DFë¼ë„ ì»¬ëŸ¼ í¬í•¨

    # âœ… ìµœì†Œ 3ê°œ ìˆ˜ì§‘ ë³´ì¥
    collected = df.copy()

    extra_fill = travel_df[
        (travel_df['ì˜ë„í…Œë§ˆëª…'].str.contains(theme, na=False)) &
        (~travel_df['ì—¬í–‰ì§€'].isin(collected['ì—¬í–‰ì§€']))
    ].drop_duplicates(subset=["ì—¬í–‰ì§€"])

    needed = 3 - len(collected)
    if needed > 0 and not extra_fill.empty:
        fill = extra_fill.sample(n=min(needed, len(extra_fill)), random_state=random.randint(1, 9999))
        collected = pd.concat([collected, fill], ignore_index=True)

    # ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ ë¬´ì‘ìœ„ë¡œ travel_dfì—ì„œ ì±„ìš°ê¸°
    if len(collected) < 3:
        fallback = travel_df[~travel_df['ì—¬í–‰ì§€'].isin(collected['ì—¬í–‰ì§€'])].drop_duplicates(subset=["ì—¬í–‰ì§€"])
        if not fallback.empty:
            fill = fallback.sample(n=min(3 - len(collected), len(fallback)), random_state=random.randint(1, 9999))
            collected = pd.concat([collected, fill], ignore_index=True)

    # âœ… í•„ìˆ˜ ì»¬ëŸ¼ ë³´ì¥
    for col in ["ì—¬í–‰ë„ì‹œ", "ì—¬í–‰ë‚˜ë¼"]:
        if col not in collected.columns:
            collected[col] = None

    # âœ… í†µí•©í…Œë§ˆëª… ë³´ì¥
    if "í†µí•©í…Œë§ˆëª…" not in collected.columns:
        collected["í†µí•©í…Œë§ˆëª…"] = theme
    else:
        collected["í†µí•©í…Œë§ˆëª…"] = collected["í†µí•©í…Œë§ˆëª…"].fillna(theme)

    return collected

    def get_festival_info(city):
        match = festival_df[festival_df['ì—¬í–‰ë„ì‹œ'] == city]
        if match.empty:
            return "ì—†ìŒ", None, None
        row = match.iloc[0]
        try:
            start = pd.to_datetime(row["ì‹œì‘ì¼"]).date()
            end = pd.to_datetime(row["ì¢…ë£Œì¼"]).date()
            if end < today:
                return "ì—†ìŒ", None, None
            return row["ì¶•ì œëª…"], start, end
        except:
            return "ì—†ìŒ", None, None
    df[["ì¶”ì²œì¶•ì œ", "ì¶•ì œì‹œì‘", "ì¶•ì œì¢…ë£Œ"]] = df["ì—¬í–‰ë„ì‹œ"].apply(lambda x: pd.Series(get_festival_info(x)))
    return df

def make_top2_description_custom(row, used_phrases=set()):
        scores = {
            k: row.get(k, 0)
            for k in ["ìˆ™ì†Œ", "ì¼ì •", "ê°€ì´ë“œ", "ì‹ì‚¬", "ê°€ì„±ë¹„", "ì´ë™ìˆ˜ë‹¨"]
        }
        top2 = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:2]
        top2_keys = frozenset([k for k, _ in top2])
        phrases = feature_phrase_map.get(top2_keys, [])

        if not phrases:
            return "", used_phrases

        available = [p for p in phrases if p not in used_phrases]
        phrase = random.choice(available) if available else random.choice(phrases)
        used_phrases.add(phrase)
        return phrase, used_phrases

def format_summary_tags_custom(summary):
    if pd.isna(summary):
        return ""
    parts = [s.strip() for s in summary.split(",") if s.strip()]
    tags = []

    i = 0
    while i < len(parts):
        part = parts[i]
        # ê°€ì´ë“œ ê²½ë¹„ ë¸”ë¡ ì²˜ë¦¬
        if "ê°€ì´ë“œ ê²½ë¹„" in part or "ê°€ì´ë“œê²½ë¹„" in part:
            guide_block = [part]
            j = i + 1
            while j < len(parts):
                next_part = parts[j]
                guide_block.append(next_part)
                if "ì„ íƒê´€ê´‘" in next_part:
                    break
                j += 1

            if len(guide_block) > 1:
                merged = "".join(guide_block[:-1]).replace(" ", "")
                tags.append(f"#{merged}")
                tags.append(f"#{guide_block[-1].strip()}")
            else:
                tags.extend(f"#{x.strip()}" for x in guide_block)

            i = j + 1
            continue

        # ì¼ë°˜ í•­ëª©
        tags.append(f"#{part}")
        i += 1

    return " ".join(tags)

def recommend_packages(
    selected_theme,
    selected_place,
    travel_df,
    package_df,
    theme_ui_map,
    chat_container=None
):
    import random

    # âœ… í†µí•© í…Œë§ˆëª… ì¶”ì¶œ
    if selected_theme in theme_ui_map:
        integrated_theme = selected_theme
    else:
        integrated_theme = (
            travel_df[
                travel_df["ì˜ë„í…Œë§ˆëª…"].str.contains(selected_theme, na=False)
            ]
            .drop_duplicates(subset=["ì—¬í–‰ì§€"])["í†µí•©í…Œë§ˆëª…"]
            .mode()
            .iloc[0]
        )

    # âœ… UI ì´ë¦„ ë° ë„ì‹œëª…
    selected_ui_name = theme_ui_map[integrated_theme][0]
    selected_city = travel_df.loc[
        travel_df["ì—¬í–‰ì§€"] == selected_place, "ì—¬í–‰ë„ì‹œ"
    ].values[0]

    # âœ… ë„ì‹œ í•„í„°
    filtered_package = package_df[
        package_df["ì—¬í–‰ë„ì‹œ"].str.contains(selected_city, na=False)
    ].copy()

    # ğŸ“ ê°ì„± ë¬¸êµ¬
    def make_top2_description(row, used_phrases=set()):
        scores = {
            k: row.get(k, 0)
            for k in ["ìˆ™ì†Œ", "ì¼ì •", "ê°€ì´ë“œ", "ì‹ì‚¬", "ê°€ì„±ë¹„", "ì´ë™ìˆ˜ë‹¨"]
        }
        top2 = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:2]
        top2_keys = frozenset([k for k, _ in top2])
        phrases = feature_phrase_map.get(top2_keys, [])

        if not phrases:
            return "", used_phrases

        available = [p for p in phrases if p not in used_phrases]
        phrase = random.choice(available) if available else random.choice(phrases)
        used_phrases.add(phrase)
        return phrase, used_phrases

    # ğŸ“ ìš”ì•½ì •ë³´ë¥¼ í•´ì‹œíƒœê·¸ë¡œ ë³€í™˜
    def format_summary_tags(summary):
        if pd.isna(summary):
            return ""
        parts = [s.strip() for s in summary.split(",") if s.strip()]
        tags = []

        i = 0
        while i < len(parts):
            part = parts[i]
            # ê°€ì´ë“œ ê²½ë¹„ ë¸”ë¡ ì²˜ë¦¬
            if "ê°€ì´ë“œ ê²½ë¹„" in part or "ê°€ì´ë“œê²½ë¹„" in part:
                guide_block = [part]
                j = i + 1
                while j < len(parts):
                    next_part = parts[j]
                    guide_block.append(next_part)
                    if "ì„ íƒê´€ê´‘" in next_part:
                        break
                    j += 1

                if len(guide_block) > 1:
                    merged = "".join(guide_block[:-1]).replace(" ", "")
                    tags.append(f"#{merged}")
                    tags.append(f"#{guide_block[-1].strip()}")
                else:
                    tags.extend(f"#{x.strip()}" for x in guide_block)

                i = j + 1
                continue

            # ì¼ë°˜ í•­ëª©
            tags.append(f"#{part}")
            i += 1

        return " ".join(tags)

    # âœ… ìƒ˜í”Œë§
    recommend_package = filtered_package.sample(
        n=min(2, len(filtered_package)),
        random_state=42
    )

    # âœ… ë¬¸êµ¬ ìƒì„±
    recommend_texts = []
    title_candidates = theme_title_phrases.get(selected_ui_name, ["ì¶”ì²œ"])
    sampled_titles = random.sample(title_candidates, k=min(2, len(title_candidates)))
    
    used_phrases = set()
    for idx, (_, row) in enumerate(recommend_package.iterrows(), 1):
        desc, used_phrases = make_top2_description(row.to_dict(), used_phrases)
        tags = format_summary_tags(row["ìš”ì•½ì •ë³´"])
        title_phrase = sampled_titles[idx - 1] if idx <= len(sampled_titles) else random.choice(title_candidates)
        title = f"{selected_city} {title_phrase} íŒ¨í‚¤ì§€"

        recommend_texts.append(
            f"""{idx}. <strong>{title}</strong><br> ğŸ…¼ {desc}<br>  {tags}<br> \
               <a href="{row.URL}" target="_blank" rel="noopener noreferrer"
           style="text-decoration:none;font-weight:600;color:#009c75;">
           ğŸ’š ë°”ë¡œê°€ê¸°&nbsp;â†—
        </a>"""
        )

    # âœ… ì¶œë ¥
    if recommend_texts:
        full_message = "ğŸ§³ ì´ëŸ° íŒ¨í‚¤ì§€ë¥¼ ì¶”ì²œë“œë ¤ìš”:<br><br>" + "<br><br>".join(recommend_texts)
        log_and_render(
            full_message,
            sender="bot",
            chat_container = chat_container,
            key="recommend_package_intro",
    )
    else:
        log_and_render(
            "âš ï¸ ì¶”ì²œ ê°€ëŠ¥í•œ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.",
            sender="bot",
            chat_container = chat_container,
            key="no_package_warning"
    )
        return
        
def handle_selected_place(selected_place, travel_df, external_score_df, festival_df, weather_df, selected_theme=None, chat_container=None):
    selected_row = travel_df[travel_df["ì—¬í–‰ì§€"] == selected_place].iloc[0]
    country = selected_row["ì—¬í–‰ë‚˜ë¼"]
    city = selected_row["ì—¬í–‰ë„ì‹œ"]

    message_lines = []
    message_lines.append(f"{selected_place}ì€(ëŠ”) {city}ì— ìœ„ì¹˜í•´ ìˆì–´ìš”.")
    message_lines.append(get_weather_message(city, weather_df))

    highlight = get_highlight_message(selected_place, travel_df, external_score_df, festival_df)
    if highlight:
        message_lines.append(highlight+"<br>")

    ##ìˆ˜ì •##
    other = travel_df[(travel_df["ì—¬í–‰ë„ì‹œ"] == city) & (travel_df["ì—¬í–‰ì§€"] != selected_place)].drop_duplicates("ì—¬í–‰ì§€")
    if not other.empty:
        other_sample = other.sample(n=min(3, len(other)), random_state=42)
        sample_names = ", ".join(other_sample["ì—¬í–‰ì§€"].tolist())
        message_lines.append(f"í•¨ê»˜ ê°€ë³´ë©´ ì¢‹ì€ ì—¬í–‰ì§€: {sample_names}")
    else:
        message_lines.append("âš ï¸ í•¨ê»˜ ê°€ë³¼ ë‹¤ë¥¸ ì—¬í–‰ì§€ê°€ ì—†ì–´ìš”.")
    # integrated_theme ì¶”ë¡  ì¶”ê°€
    if selected_theme is None:
        theme_row = travel_df[travel_df["ì—¬í–‰ì§€"] == selected_place]
        if not theme_row.empty and pd.notna(theme_row.iloc[0]["í†µí•©í…Œë§ˆëª…"]):
            selected_theme = theme_row.iloc[0]["í†µí•©í…Œë§ˆëª…"]

    full_message = "<br>".join(message_lines)

    log_and_render(
        full_message,
        sender="bot",
        key=f"region_detail_{selected_place}",
        chat_container=chat_container
    )

    recommend_packages(
        selected_theme=selected_theme,
        selected_place=selected_place,
        travel_df=travel_df,
        package_df=package_df,
        theme_ui_map=theme_ui_map,
        chat_container=chat_container
    )

def main():
    user_input = input("ìš”ì¦˜, ì–´ë–¤ ì—¬í–‰ì´ ë– ì˜¤ë¥´ì‹œë‚˜ìš”?")

    # 1. ê°ì • ë° ì˜ë„ ë¶„ì„
    top_emotions, emotion_groups = analyze_emotion(user_input)
    intent, intent_score = detect_intent(user_input)
    country_filter, city_filter = detect_location_filter(user_input)

    if country_filter or city_filter:
        loc_str = f"{country_filter or ''} {city_filter or ''}".strip()
        print(f"ğŸ” '{city_filter or country_filter}'ì— í•´ë‹¹í•˜ëŠ” ì—¬í–‰ì§€ë“¤ë§Œ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œë“œë¦´ê²Œìš”!")
        
    candidate_themes = extract_themes(emotion_groups, intent, force_mode=(intent_score >= 0.7))

    # 2. ì¶œë ¥
    print("\n[ê°ì • ë¶„ì„ ê²°ê³¼]")
    for emo, score in top_emotions:
        print(f"- {emo}: {score:.2f}%")
    print(f"\n[ì˜ë„ íŒë‹¨ ê²°ê³¼] â†’ {intent} (ìœ ì‚¬ë„: {intent_score:.2f})")

    # 3. ì¡°ê±´ ë¶„ê¸°

    # âœ… case 1: intent ê¸°ë°˜ ì¶”ì²œ
    if intent_score >= 0.70:
        selected_theme = intent
        print(f"\n[ëª…í™•í•œ ì˜ë„ì— ë”°ë¼ ìë™ ì¶”ì²œ í…Œë§ˆ ì„ íƒë¨] â†’ {selected_theme}")
        
        # ì˜ë„ ì˜¤í”„ë‹ ë¬¸êµ¬ ì¶œë ¥
        ui_name = theme_ui_map.get(selected_theme, (selected_theme,))[0]
        opening_line = (
            theme_opening_lines.get(ui_name)
            or intent_opening_lines.get(selected_theme)
            or None
        )
        if opening_line:
            print(f"\n{opening_line}")
    
        theme_df = recommend_places_by_theme(selected_theme, country_filter, city_filter)
        theme_df = theme_df.drop_duplicates(subset=["ì—¬í–‰ì§€"])
        result_df = apply_weighted_score_filter(theme_df)
        
        if len(result_df) < 3:            
            fallback = travel_df[~travel_df['ì—¬í–‰ì§€'].isin(result_df['ì—¬í–‰ì§€'])].drop_duplicates(subset=["ì—¬í–‰ì§€"])
            if not fallback.empty:
                fill = fallback.sample(n=min(3 - len(result_df), len(fallback)), random_state=random.randint(1, 9999))
                result_df = pd.concat([result_df, fill], ignore_index=True)
                
    # âœ… case 2: í›„ë³´ í…Œë§ˆê°€ 1ê°œ
    elif len(candidate_themes) == 1:
        selected_theme = candidate_themes[0]
        print(f"\nì¶”ì²œ ê°€ëŠ¥í•œ í…Œë§ˆê°€ 1ê°œì´ë¯€ë¡œ ìë™ ì„ íƒ: {selected_theme}")
        theme_df = recommend_places_by_theme(selected_theme, country_filter, city_filter)
        theme_df = theme_df.drop_duplicates(subset=["ì—¬í–‰ì§€"])
        result_df = apply_weighted_score_filter(theme_df)

        if len(result_df) < 3:            
            fallback = travel_df[~travel_df['ì—¬í–‰ì§€'].isin(result_df['ì—¬í–‰ì§€'])].drop_duplicates(subset=["ì—¬í–‰ì§€"])
            if not fallback.empty:
                fill = fallback.sample(n=min(3 - len(result_df), len(fallback)), random_state=random.randint(1, 9999))
                result_df = pd.concat([result_df, fill], ignore_index=True)
                
    # âœ… case 3: ë³µìˆ˜ í…Œë§ˆ â†’ ì‚¬ìš©ì ì„ íƒ
    else:
        # ë³µìˆ˜ í…Œë§ˆì˜ ì—¬í–‰ì§€ ì „ì²´ ìˆ˜ì§‘
        all_theme_df = pd.concat([
            recommend_places_by_theme(t, country_filter, city_filter) for t in candidate_themes
        ])
        all_theme_df = all_theme_df.drop_duplicates(subset=["ì—¬í–‰ì§€"])

        # í†µí•©í…Œë§ˆëª… ëª©ë¡ ì¶”ì¶œ
        # 5. ìµœì¢… ë³‘í•©
        filtered = pd.merge(
            all_theme_df,
            external_score_df[["ì—¬í–‰ë‚˜ë¼", "ì—¬í–‰ë„ì‹œ"]],
            on=["ì—¬í–‰ë‚˜ë¼", "ì—¬í–‰ë„ì‹œ"],
            how="inner"
        ).drop_duplicates(subset=["ì—¬í–‰ì§€"])

        # 2) ì¤‘ë³µ ì œê±° í›„ ìµœì¢… í…Œë§ˆ ëª©ë¡
        filtered = filtered.drop_duplicates(subset=['ì—¬í–‰ì§€'])
        available_themes = filtered['í†µí•©í…Œë§ˆëª…'].dropna().unique().tolist()[:3] ##[:3] ê°€ê°€
        
        # ğŸ’¡ ê°ì„± UI í¬ë§·ìœ¼ë¡œ ì¶œë ¥
        print("\nì¶”ì²œ ê°€ëŠ¥í•œ ì—¬í–‰ í…Œë§ˆ:")
        for idx, theme in enumerate(available_themes, 1):
            ui_name, ui_desc = theme_ui_map.get(theme, (theme, ""))
            print(f"{idx}. {ui_name} â€“ {ui_desc}")
        
        print("\nğŸ‘‰ ì–´ë–¤ í…Œë§ˆê°€ ëŒë¦¬ì‹œë‚˜ìš”?")
        print(" ".join(f"[{theme_ui_map.get(t, (t,))[0]}]" for t in available_themes))
        
        # ìë™ ì„ íƒ or ì‚¬ìš©ì ì…ë ¥
        if len(available_themes) == 1:
            selected_ui_name = theme_ui_map.get(available_themes[0], (available_themes[0], ""))[0]
            selected_theme = ui_to_theme_map[selected_ui_name]
            print(f"\nì¶”ì²œ ê°€ëŠ¥í•œ í…Œë§ˆê°€ 1ê°œì´ë¯€ë¡œ ìë™ ì„ íƒ: {selected_ui_name}")
        else:
            sel = int(input("\nì›í•˜ëŠ” í…Œë§ˆ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: ")) - 1
            selected_ui_name = theme_ui_map.get(available_themes[sel], (available_themes[sel], ""))[0]
            selected_theme = ui_to_theme_map[selected_ui_name]
            print(f"\nì„ íƒí•˜ì‹  í…Œë§ˆ: {selected_ui_name}")

        # í•´ë‹¹ í…Œë§ˆ ê¸°ì¤€ ìµœì¢… ì¶”ì²œ
        theme_df = all_theme_df[all_theme_df["í†µí•©í…Œë§ˆëª…"] == selected_theme]
        theme_df = theme_df.drop_duplicates(subset=["ì—¬í–‰ì§€"])
        result_df = apply_weighted_score_filter(theme_df)

        ###ì¶”ê°€###
        if len(result_df) < 3:            
            fallback = travel_df[~travel_df['ì—¬í–‰ì§€'].isin(result_df['ì—¬í–‰ì§€'])].drop_duplicates(subset=["ì—¬í–‰ì§€"])
            if not fallback.empty:
                fill = fallback.sample(n=min(3 - len(result_df), len(fallback)), random_state=random.randint(1, 9999))
                result_df = pd.concat([result_df, fill], ignore_index=True)
        
    # 4. ê²°ê³¼ ì¶œë ¥
    if intent_score < 0.7:  # ê°ì • ê¸°ë°˜ì¸ ê²½ìš°ì—ë§Œ ì¶œë ¥
        ui_name = theme_ui_map.get(selected_theme, (selected_theme,))[0]
        opening_line_template = theme_opening_lines.get(ui_name)
        if opening_line_template:
            print(f"\n{opening_line_template.format(len(result_df))}")
    
    print("\n[ìµœì¢… ì¶”ì²œ ì—¬í–‰ì§€]")
    for idx, row in enumerate(result_df.itertuples(), 1):
        country = row.ì—¬í–‰ë‚˜ë¼
        city = row.ì—¬í–‰ë„ì‹œ
        name = row.ì—¬í–‰ì§€
        desc = row.í•œì¤„ì„¤ëª… if hasattr(row, 'í•œì¤„ì„¤ëª…') else "ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤"

        if country == city:
            loc = f"{country}"
        else:
            loc = f"{country}, {city}"

        print(f"{idx}. {name} ({loc}) - {desc}")

    recommend_names = result_df["ì—¬í–‰ì§€"].tolist()

    print("\nğŸ‘‰ ë§ˆìŒì— ë“œëŠ” ì—¬í–‰ì§€ë¥¼ ê³¨ë¼ì£¼ì„¸ìš”:")
    print(" ".join(f"[{name}]" for name in recommend_names))
        
    try:
        sel = int(input("\nì›í•˜ëŠ” ì—¬í–‰ì§€ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:")) - 1
        if 0 <= sel < len(recommend_names):
            selected_place = recommend_names[sel]
            print(f"\nğŸ‰ '{selected_place}'ë¥¼ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. ë©‹ì§„ ì—¬í–‰ ë˜ì„¸ìš”!")
        else:
            print("\nâš ï¸ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    except ValueError:
        print("\nâš ï¸ ìˆ«ìë¡œ ëœ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# In[12]:


# if __name__ == "__main__":
#main()


# In[ ]:




